{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "da899da43bf042acba911c8470000c0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f2de46bc59d34035a390faf70e7508df",
              "IPY_MODEL_a4aebf1b0021428dbfdb28ed9a674ac1",
              "IPY_MODEL_dba4cfe006fe41d8b9df63e1240df24b"
            ],
            "layout": "IPY_MODEL_0932726cb03f424b84a8c2c809280253"
          }
        },
        "f2de46bc59d34035a390faf70e7508df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d89eabb64af04458b65a0272a38a9c31",
            "placeholder": "​",
            "style": "IPY_MODEL_75c2671d9550471585ca654b0d777f9b",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "a4aebf1b0021428dbfdb28ed9a674ac1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c32948c14adf460da73b5d6138c2759a",
            "max": 605,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0584866c38804efea8cfc1d97e5df8e6",
            "value": 605
          }
        },
        "dba4cfe006fe41d8b9df63e1240df24b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_88de4dca08f3485db074e0095fe1a6a4",
            "placeholder": "​",
            "style": "IPY_MODEL_b5621ab72b2e4d7e9a7e3997818ef6a9",
            "value": " 605/605 [00:00&lt;00:00, 32.6kB/s]"
          }
        },
        "0932726cb03f424b84a8c2c809280253": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d89eabb64af04458b65a0272a38a9c31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75c2671d9550471585ca654b0d777f9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c32948c14adf460da73b5d6138c2759a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0584866c38804efea8cfc1d97e5df8e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "88de4dca08f3485db074e0095fe1a6a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5621ab72b2e4d7e9a7e3997818ef6a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Ou4mJql897v",
        "outputId": "c4eeb4d8-885c-46d5-8c20-55ade80f6d02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting musiclm-pytorch\n",
            "  Downloading musiclm_pytorch-0.2.2-py3-none-any.whl (12 kB)\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-0.18.0-py3-none-any.whl (215 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m215.3/215.3 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting beartype\n",
            "  Downloading beartype-0.13.1-py3-none-any.whl (707 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m708.0/708.0 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting x-clip\n",
            "  Downloading x_clip-0.12.1-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting vector-quantize-pytorch>=1.0.0\n",
            "  Downloading vector_quantize_pytorch-1.2.2-py3-none-any.whl (10 kB)\n",
            "Collecting audiolm-pytorch>=0.17.0\n",
            "  Downloading audiolm_pytorch-0.27.4-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: torch>=1.12 in /usr/local/lib/python3.9/dist-packages (from musiclm-pytorch) (2.0.0+cu118)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.9/dist-packages (from musiclm-pytorch) (2.0.1+cu118)\n",
            "Collecting lion-pytorch\n",
            "  Downloading lion_pytorch-0.0.7-py3-none-any.whl (4.3 kB)\n",
            "Collecting einops>=0.6\n",
            "  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from audiolm-pytorch>=0.17.0->musiclm-pytorch) (4.65.0)\n",
            "Collecting local-attention>=1.8.4\n",
            "  Downloading local_attention-1.8.5-py3-none-any.whl (8.1 kB)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from audiolm-pytorch>=0.17.0->musiclm-pytorch) (1.2.0)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.98-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting encodec\n",
            "  Downloading encodec-0.1.1.tar.gz (3.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m65.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ema-pytorch>=0.2.2\n",
            "  Downloading ema_pytorch-0.2.3-py3-none-any.whl (4.4 kB)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fairseq\n",
            "  Downloading fairseq-0.12.2.tar.gz (9.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (from audiolm-pytorch>=0.17.0->musiclm-pytorch) (1.2.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch>=1.12->musiclm-pytorch) (1.11.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch>=1.12->musiclm-pytorch) (2.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch>=1.12->musiclm-pytorch) (3.11.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch>=1.12->musiclm-pytorch) (3.1.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch>=1.12->musiclm-pytorch) (3.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.12->musiclm-pytorch) (4.5.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.12->musiclm-pytorch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.12->musiclm-pytorch) (16.0.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.9/dist-packages (from accelerate->musiclm-pytorch) (6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from accelerate->musiclm-pytorch) (5.9.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from accelerate->musiclm-pytorch) (23.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from accelerate->musiclm-pytorch) (1.22.4)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (from x-clip->musiclm-pytorch) (0.15.1+cu118)\n",
            "Collecting ftfy\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.9/dist-packages (from x-clip->musiclm-pytorch) (2022.10.31)\n",
            "Collecting omegaconf<2.1\n",
            "  Downloading omegaconf-2.0.6-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.9/dist-packages (from fairseq->audiolm-pytorch>=0.17.0->musiclm-pytorch) (0.29.34)\n",
            "Collecting bitarray\n",
            "  Downloading bitarray-2.7.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (269 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m269.6/269.6 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sacrebleu>=1.4.12\n",
            "  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cffi in /usr/local/lib/python3.9/dist-packages (from fairseq->audiolm-pytorch>=0.17.0->musiclm-pytorch) (1.15.1)\n",
            "Collecting hydra-core<1.1,>=1.0.7\n",
            "  Downloading hydra_core-1.0.7-py3-none-any.whl (123 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.9/dist-packages (from ftfy->x-clip->musiclm-pytorch) (0.2.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch>=1.12->musiclm-pytorch) (2.1.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->audiolm-pytorch>=0.17.0->musiclm-pytorch) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->audiolm-pytorch>=0.17.0->musiclm-pytorch) (1.10.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch>=1.12->musiclm-pytorch) (1.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchvision->x-clip->musiclm-pytorch) (2.27.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision->x-clip->musiclm-pytorch) (8.4.0)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.14.0-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.2/224.2 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m87.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers->audiolm-pytorch>=0.17.0->musiclm-pytorch) (2023.4.0)\n",
            "Collecting antlr4-python3-runtime==4.8\n",
            "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.4/112.4 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.9/dist-packages (from sacrebleu>=1.4.12->fairseq->audiolm-pytorch>=0.17.0->musiclm-pytorch) (4.9.2)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.9/dist-packages (from sacrebleu>=1.4.12->fairseq->audiolm-pytorch>=0.17.0->musiclm-pytorch) (0.8.10)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.9/dist-packages (from cffi->fairseq->audiolm-pytorch>=0.17.0->musiclm-pytorch) (2.21)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision->x-clip->musiclm-pytorch) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision->x-clip->musiclm-pytorch) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision->x-clip->musiclm-pytorch) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision->x-clip->musiclm-pytorch) (2.0.12)\n",
            "Building wheels for collected packages: encodec, fairseq, antlr4-python3-runtime\n",
            "  Building wheel for encodec (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for encodec: filename=encodec-0.1.1-py3-none-any.whl size=45775 sha256=05e28c54ccced3c72ee2a48993929be7babdbcd4fdf2533ee91a0146dbf2fc87\n",
            "  Stored in directory: /root/.cache/pip/wheels/1d/9d/20/489d6aafffb505e18fcfcfbe722562f91c26af0a8a6da7d00b\n",
            "  Building wheel for fairseq (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairseq: filename=fairseq-0.12.2-cp39-cp39-linux_x86_64.whl size=11180078 sha256=07a64f48eafc8bd5a2744726ffcafc852a021d7cfa0463635940e9ae3fe15500\n",
            "  Stored in directory: /root/.cache/pip/wheels/59/35/87/2baf2e4ad37c83fd698c486b3d39f0e7022226fa52ab469c31\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141229 sha256=c4d6d8f6b1d8fa0b0ff9242661739a7bed28ab8bad5de33055e320b79b9157fc\n",
            "  Stored in directory: /root/.cache/pip/wheels/42/3c/ae/14db087e6018de74810afe32eb6ac890ef9c68ba19b00db97a\n",
            "Successfully built encodec fairseq antlr4-python3-runtime\n",
            "Installing collected packages: tokenizers, sentencepiece, bitarray, antlr4-python3-runtime, portalocker, omegaconf, ftfy, einops, colorama, beartype, sacrebleu, hydra-core, huggingface-hub, transformers, vector-quantize-pytorch, local-attention, lion-pytorch, fairseq, encodec, ema-pytorch, accelerate, x-clip, audiolm-pytorch, musiclm-pytorch\n",
            "Successfully installed accelerate-0.18.0 antlr4-python3-runtime-4.8 audiolm-pytorch-0.27.4 beartype-0.13.1 bitarray-2.7.3 colorama-0.4.6 einops-0.6.1 ema-pytorch-0.2.3 encodec-0.1.1 fairseq-0.12.2 ftfy-6.1.1 huggingface-hub-0.14.0 hydra-core-1.0.7 lion-pytorch-0.0.7 local-attention-1.8.5 musiclm-pytorch-0.2.2 omegaconf-2.0.6 portalocker-2.7.0 sacrebleu-2.3.1 sentencepiece-0.1.98 tokenizers-0.13.3 transformers-4.28.1 vector-quantize-pytorch-1.2.2 x-clip-0.12.1\n"
          ]
        }
      ],
      "source": [
        "!pip install musiclm-pytorch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from musiclm_pytorch import MuLaN, AudioSpectrogramTransformer, TextTransformer\n",
        "\n",
        "audio_transformer = AudioSpectrogramTransformer(\n",
        "    dim = 512,\n",
        "    depth = 6,\n",
        "    heads = 8,\n",
        "    dim_head = 64,\n",
        "    spec_n_fft = 128,\n",
        "    spec_win_length = 24,\n",
        "    spec_aug_stretch_factor = 0.8\n",
        ")\n",
        "\n",
        "text_transformer = TextTransformer(\n",
        "    dim = 512,\n",
        "    depth = 6,\n",
        "    heads = 8,\n",
        "    dim_head = 64\n",
        ")\n",
        "\n",
        "mulan = MuLaN(\n",
        "    audio_transformer = audio_transformer,\n",
        "    text_transformer = text_transformer\n",
        ")\n",
        "\n",
        "# get a ton of <sound, text> pairs and train\n",
        "\n",
        "wavs = torch.randn(2, 1024)\n",
        "texts = torch.randint(0, 20000, (2, 256))\n",
        "\n",
        "loss = mulan(wavs, texts)\n",
        "loss.backward()\n",
        "\n",
        "# after much training, you can embed sounds and text into a joint embedding space\n",
        "# for conditioning the audio LM\n",
        "\n",
        "embeds = mulan.get_audio_latents(wavs)  # during training\n",
        "\n",
        "embeds = mulan.get_text_latents(texts)  # during inference"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNuvd8zII4GJ",
        "outputId": "b1a7e454-264a-4a75-b7cb-4d1e4129571b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "spectrogram yielded shape of (65, 86), but had to be cropped to (64, 80) to be patchified for transformer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from musiclm_pytorch import MuLaNEmbedQuantizer\n",
        "\n",
        "# setup the quantizer with the namespaced conditioning embeddings, unique per quantizer as well as namespace (per transformer)\n",
        "\n",
        "quantizer = MuLaNEmbedQuantizer(\n",
        "    mulan = mulan,                          # pass in trained mulan from above\n",
        "    conditioning_dims = (1024, 1024, 1024), # say all three transformers have model dimensions of 1024\n",
        "    namespaces = ('semantic', 'coarse', 'fine')\n",
        ")\n",
        "\n",
        "# now say you want the conditioning embeddings for semantic transformer\n",
        "\n",
        "wavs = torch.randn(2, 1024)\n",
        "conds = quantizer(wavs = wavs, namespace = 'semantic') # (2, 8, 1024) - 8 is number of quantizers"
      ],
      "metadata": {
        "id": "MXqEvhVLJCua"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1m7JWs926JPN",
        "outputId": "7e15cd4c-4a15-4cfd-babe-d7f0d8156e07"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from audiolm_pytorch import SoundStream, SoundStreamTrainer\n",
        "\n",
        "soundstream = SoundStream(\n",
        "    codebook_size = 1024,\n",
        "    rq_num_quantizers = 8,\n",
        "    attn_window_size = 128,       # local attention receptive field at bottleneck\n",
        "    attn_depth = 2                # 2 local attention transformer blocks - the soundstream folks were not experts with attention, so i took the liberty to add some. encodec went with lstms, but attention should be better\n",
        ")\n",
        "\n",
        "trainer = SoundStreamTrainer(\n",
        "    soundstream,\n",
        "    folder = '/content/drive/MyDrive/ArtML_Final/recordings',\n",
        "    batch_size = 4,\n",
        "    grad_accum_every = 8,         # effective batch size of 32\n",
        "    data_max_length_seconds = 2,  # train on 2 second audio\n",
        "    num_train_steps = 20\n",
        ").cuda()\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xk4ZpDiGl5Tv",
        "outputId": "a4913063-9ef6-41cb-fdc5-79144c7c1670"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training with dataset of 2850 samples and validating with randomly splitted 150 samples\n",
            "0: soundstream total loss: 11.102, soundstream recon loss: 0.010 | discr (scale 1) loss: 2.000 | discr (scale 0.5) loss: 2.000 | discr (scale 0.25) loss: 2.000\n",
            "0: saving to results\n",
            "0: saving model to results\n",
            "1: soundstream total loss: 7.185, soundstream recon loss: 0.002 | discr (scale 1) loss: 2.001 | discr (scale 0.5) loss: 2.001 | discr (scale 0.25) loss: 2.001\n",
            "2: soundstream total loss: 9.004, soundstream recon loss: 0.003 | discr (scale 1) loss: 2.000 | discr (scale 0.5) loss: 2.001 | discr (scale 0.25) loss: 2.002\n",
            "3: soundstream total loss: 12.161, soundstream recon loss: 0.003 | discr (scale 1) loss: 1.998 | discr (scale 0.5) loss: 2.000 | discr (scale 0.25) loss: 2.000\n",
            "4: soundstream total loss: 12.067, soundstream recon loss: 0.003 | discr (scale 1) loss: 1.997 | discr (scale 0.5) loss: 2.000 | discr (scale 0.25) loss: 2.000\n",
            "5: soundstream total loss: 8.345, soundstream recon loss: 0.001 | discr (scale 1) loss: 1.999 | discr (scale 0.5) loss: 2.001 | discr (scale 0.25) loss: 2.001\n",
            "6: soundstream total loss: 7.090, soundstream recon loss: 0.001 | discr (scale 1) loss: 2.004 | discr (scale 0.5) loss: 2.002 | discr (scale 0.25) loss: 2.002\n",
            "7: soundstream total loss: 7.676, soundstream recon loss: 0.001 | discr (scale 1) loss: 2.007 | discr (scale 0.5) loss: 2.001 | discr (scale 0.25) loss: 2.001\n",
            "8: soundstream total loss: 6.483, soundstream recon loss: 0.001 | discr (scale 1) loss: 2.007 | discr (scale 0.5) loss: 2.000 | discr (scale 0.25) loss: 2.000\n",
            "9: soundstream total loss: 4.745, soundstream recon loss: 0.001 | discr (scale 1) loss: 2.008 | discr (scale 0.5) loss: 1.999 | discr (scale 0.25) loss: 1.999\n",
            "10: soundstream total loss: 6.068, soundstream recon loss: 0.001 | discr (scale 1) loss: 2.005 | discr (scale 0.5) loss: 1.999 | discr (scale 0.25) loss: 1.999\n",
            "11: soundstream total loss: 4.462, soundstream recon loss: 0.001 | discr (scale 1) loss: 2.002 | discr (scale 0.5) loss: 2.000 | discr (scale 0.25) loss: 2.000\n",
            "12: soundstream total loss: 4.754, soundstream recon loss: 0.001 | discr (scale 1) loss: 1.997 | discr (scale 0.5) loss: 2.000 | discr (scale 0.25) loss: 2.000\n",
            "13: soundstream total loss: 3.899, soundstream recon loss: 0.001 | discr (scale 1) loss: 1.997 | discr (scale 0.5) loss: 1.999 | discr (scale 0.25) loss: 1.999\n",
            "14: soundstream total loss: 3.806, soundstream recon loss: 0.001 | discr (scale 1) loss: 1.997 | discr (scale 0.5) loss: 1.999 | discr (scale 0.25) loss: 1.999\n",
            "15: soundstream total loss: 3.335, soundstream recon loss: 0.001 | discr (scale 1) loss: 1.998 | discr (scale 0.5) loss: 2.001 | discr (scale 0.25) loss: 2.002\n",
            "16: soundstream total loss: 3.171, soundstream recon loss: 0.001 | discr (scale 1) loss: 2.002 | discr (scale 0.5) loss: 2.001 | discr (scale 0.25) loss: 2.002\n",
            "17: soundstream total loss: 3.502, soundstream recon loss: 0.001 | discr (scale 1) loss: 2.005 | discr (scale 0.5) loss: 1.998 | discr (scale 0.25) loss: 1.999\n",
            "18: soundstream total loss: 3.062, soundstream recon loss: 0.001 | discr (scale 1) loss: 2.004 | discr (scale 0.5) loss: 1.998 | discr (scale 0.25) loss: 2.000\n",
            "19: soundstream total loss: 3.035, soundstream recon loss: 0.001 | discr (scale 1) loss: 2.001 | discr (scale 0.5) loss: 2.000 | discr (scale 0.25) loss: 2.001\n",
            "training complete\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from audiolm_pytorch import HubertWithKmeans, SemanticTransformer, SemanticTransformerTrainer\n",
        "\n",
        "wav2vec = HubertWithKmeans(\n",
        "    checkpoint_path = '/content/drive/MyDrive/ArtML_Final/hubert_base_ls960.pt',\n",
        "    kmeans_path = '/content/drive/MyDrive/ArtML_Final/hubert_base_ls960_L9_km500.bin'\n",
        ")\n",
        "\n",
        "semantic_transformer = SemanticTransformer(\n",
        "    num_semantic_tokens = wav2vec.codebook_size,\n",
        "    dim = 1024,\n",
        "    depth = 6,\n",
        "    audio_text_condition = True      # this must be set to True (same for CoarseTransformer and FineTransformers)\n",
        ").cuda()\n",
        "\n",
        "trainer = SemanticTransformerTrainer(\n",
        "    transformer = semantic_transformer,\n",
        "    wav2vec = wav2vec,\n",
        "    audio_conditioner = quantizer,   # pass in the MulanEmbedQuantizer instance above\n",
        "    folder ='/content/drive/MyDrive/ArtML_Final/recordings',\n",
        "    batch_size = 1,\n",
        "    data_max_length = 320 * 32,\n",
        "    num_train_steps = 1000\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "da899da43bf042acba911c8470000c0d",
            "f2de46bc59d34035a390faf70e7508df",
            "a4aebf1b0021428dbfdb28ed9a674ac1",
            "dba4cfe006fe41d8b9df63e1240df24b",
            "0932726cb03f424b84a8c2c809280253",
            "d89eabb64af04458b65a0272a38a9c31",
            "75c2671d9550471585ca654b0d777f9b",
            "c32948c14adf460da73b5d6138c2759a",
            "0584866c38804efea8cfc1d97e5df8e6",
            "88de4dca08f3485db074e0095fe1a6a4",
            "b5621ab72b2e4d7e9a7e3997818ef6a9"
          ]
        },
        "id": "jiAghvXgJR2J",
        "outputId": "6cd2aef6-73fe-4ced-c24d-14726b0606d4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator MiniBatchKMeans from version 0.24.0 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/605 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "da899da43bf042acba911c8470000c0d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training with dataset of 2850 samples and validating with randomly splitted 150 samples\n",
            "do you want to clear previous experiment checkpoints and results? (y/n) y\n",
            "0: loss: 6.196114540100098\n",
            "0: valid loss 6.128756999969482\n",
            "0: saving model to results\n",
            "1: loss: 6.42691707611084\n",
            "2: loss: 5.791701793670654\n",
            "3: loss: 4.1556620597839355\n",
            "4: loss: 4.668427467346191\n",
            "5: loss: 5.722742557525635\n",
            "6: loss: 4.83859395980835\n",
            "7: loss: 5.2559733390808105\n",
            "8: loss: 6.645999431610107\n",
            "9: loss: 4.512092113494873\n",
            "10: loss: 6.284344673156738\n",
            "11: loss: 6.3512725830078125\n",
            "12: loss: 5.7947797775268555\n",
            "13: loss: 4.565145015716553\n",
            "14: loss: 4.949483394622803\n",
            "15: loss: 4.728059768676758\n",
            "16: loss: 5.563417911529541\n",
            "17: loss: 4.71204948425293\n",
            "18: loss: 4.797524929046631\n",
            "19: loss: 6.340610027313232\n",
            "20: loss: 4.45046329498291\n",
            "21: loss: 4.403565406799316\n",
            "22: loss: 5.140037536621094\n",
            "23: loss: 4.427911758422852\n",
            "24: loss: 4.4180779457092285\n",
            "25: loss: 4.2119293212890625\n",
            "26: loss: 4.418458938598633\n",
            "27: loss: 5.197200775146484\n",
            "28: loss: 4.918365478515625\n",
            "29: loss: 5.483386993408203\n",
            "30: loss: 4.099637508392334\n",
            "31: loss: 4.079738616943359\n",
            "32: loss: 6.1668701171875\n",
            "33: loss: 4.719995975494385\n",
            "34: loss: 4.280557155609131\n",
            "35: loss: 5.176051139831543\n",
            "36: loss: 2.9791438579559326\n",
            "37: loss: 5.386986255645752\n",
            "38: loss: 5.4298996925354\n",
            "39: loss: 4.470810413360596\n",
            "40: loss: 4.551779270172119\n",
            "41: loss: 6.366311550140381\n",
            "42: loss: 3.4571690559387207\n",
            "43: loss: 3.8728413581848145\n",
            "44: loss: 3.3410403728485107\n",
            "45: loss: 4.147636890411377\n",
            "46: loss: 5.624405860900879\n",
            "47: loss: 4.319314479827881\n",
            "48: loss: 4.643031597137451\n",
            "49: loss: 3.573840856552124\n",
            "50: loss: 3.836519718170166\n",
            "51: loss: 3.646693468093872\n",
            "52: loss: 3.2836666107177734\n",
            "53: loss: 4.323949337005615\n",
            "54: loss: 3.979464292526245\n",
            "55: loss: 4.366615295410156\n",
            "56: loss: 4.6966328620910645\n",
            "57: loss: 4.181918144226074\n",
            "58: loss: 5.950848579406738\n",
            "59: loss: 3.954253911972046\n",
            "60: loss: 4.116333961486816\n",
            "61: loss: 4.354850769042969\n",
            "62: loss: 2.7210724353790283\n",
            "63: loss: 3.1836771965026855\n",
            "64: loss: 4.1147637367248535\n",
            "65: loss: 2.9287338256835938\n",
            "66: loss: 2.082828998565674\n",
            "67: loss: 5.665258407592773\n",
            "68: loss: 5.364367961883545\n",
            "69: loss: 4.887761116027832\n",
            "70: loss: 4.715466022491455\n",
            "71: loss: 3.9197027683258057\n",
            "72: loss: 3.43967604637146\n",
            "73: loss: 3.728102207183838\n",
            "74: loss: 3.9431967735290527\n",
            "75: loss: 3.329744577407837\n",
            "76: loss: 3.484818458557129\n",
            "77: loss: 2.7764484882354736\n",
            "78: loss: 4.973525047302246\n",
            "79: loss: 2.7795422077178955\n",
            "80: loss: 5.172384738922119\n",
            "81: loss: 3.5522966384887695\n",
            "82: loss: 4.324604511260986\n",
            "83: loss: 3.4819557666778564\n",
            "84: loss: 2.375413179397583\n",
            "85: loss: 4.069152355194092\n",
            "86: loss: 4.561888694763184\n",
            "87: loss: 3.473604679107666\n",
            "88: loss: 5.290376663208008\n",
            "89: loss: 3.87054443359375\n",
            "90: loss: 3.2953524589538574\n",
            "91: loss: 3.057600736618042\n",
            "92: loss: 4.901777267456055\n",
            "93: loss: 4.5515642166137695\n",
            "94: loss: 3.1676719188690186\n",
            "95: loss: 2.5231082439422607\n",
            "96: loss: 3.3485300540924072\n",
            "97: loss: 3.1864447593688965\n",
            "98: loss: 4.974342346191406\n",
            "99: loss: 3.6241679191589355\n",
            "100: loss: 4.153201103210449\n",
            "100: valid loss 5.259486198425293\n",
            "101: loss: 3.6645047664642334\n",
            "102: loss: 3.4309661388397217\n",
            "103: loss: 4.220698356628418\n",
            "104: loss: 3.1940701007843018\n",
            "105: loss: 4.007809162139893\n",
            "106: loss: 3.1817686557769775\n",
            "107: loss: 3.8362464904785156\n",
            "108: loss: 2.940803289413452\n",
            "109: loss: 3.79130220413208\n",
            "110: loss: 3.8884546756744385\n",
            "111: loss: 3.2773702144622803\n",
            "112: loss: 3.3702714443206787\n",
            "113: loss: 3.410557270050049\n",
            "114: loss: 4.309948444366455\n",
            "115: loss: 4.464212894439697\n",
            "116: loss: 4.217759609222412\n",
            "117: loss: 3.369658946990967\n",
            "118: loss: 3.4994869232177734\n",
            "119: loss: 3.4173378944396973\n",
            "120: loss: 3.4468235969543457\n",
            "121: loss: 3.0010271072387695\n",
            "122: loss: 2.5322821140289307\n",
            "123: loss: 4.649626731872559\n",
            "124: loss: 3.0139918327331543\n",
            "125: loss: 4.467169284820557\n",
            "126: loss: 3.1833128929138184\n",
            "127: loss: 3.4907026290893555\n",
            "128: loss: 2.3450911045074463\n",
            "129: loss: 2.119433641433716\n",
            "130: loss: 3.817115306854248\n",
            "131: loss: 3.4717929363250732\n",
            "132: loss: 4.042921543121338\n",
            "133: loss: 4.4673919677734375\n",
            "134: loss: 3.1217644214630127\n",
            "135: loss: 4.112013816833496\n",
            "136: loss: 3.1205520629882812\n",
            "137: loss: 3.1397299766540527\n",
            "138: loss: 4.724010467529297\n",
            "139: loss: 3.92632794380188\n",
            "140: loss: 3.5339174270629883\n",
            "141: loss: 3.5219690799713135\n",
            "142: loss: 5.024521827697754\n",
            "143: loss: 3.781252861022949\n",
            "144: loss: 3.589132785797119\n",
            "145: loss: 2.933840036392212\n",
            "146: loss: 4.5044684410095215\n",
            "147: loss: 4.291961669921875\n",
            "148: loss: 2.7863521575927734\n",
            "149: loss: 2.4706461429595947\n",
            "150: loss: 4.266205310821533\n",
            "151: loss: 4.261935234069824\n",
            "152: loss: 3.6255154609680176\n",
            "153: loss: 3.6392109394073486\n",
            "154: loss: 2.71246337890625\n",
            "155: loss: 2.950896739959717\n",
            "156: loss: 3.187749147415161\n",
            "157: loss: 2.994297504425049\n",
            "158: loss: 2.9935314655303955\n",
            "159: loss: 2.9162185192108154\n",
            "160: loss: 3.987612247467041\n",
            "161: loss: 2.8954062461853027\n",
            "162: loss: 2.111473560333252\n",
            "163: loss: 2.8991687297821045\n",
            "164: loss: 2.5696277618408203\n",
            "165: loss: 2.78615665435791\n",
            "166: loss: 2.7207212448120117\n",
            "167: loss: 3.220519542694092\n",
            "168: loss: 4.011989116668701\n",
            "169: loss: 4.065578460693359\n",
            "170: loss: 4.373760223388672\n",
            "171: loss: 3.2755753993988037\n",
            "172: loss: 4.710782051086426\n",
            "173: loss: 3.186551809310913\n",
            "174: loss: 3.3628172874450684\n",
            "175: loss: 3.9154739379882812\n",
            "176: loss: 3.0420801639556885\n",
            "177: loss: 4.071237087249756\n",
            "178: loss: 3.4177637100219727\n",
            "179: loss: 3.2953426837921143\n",
            "180: loss: 4.25266170501709\n",
            "181: loss: 4.055235862731934\n",
            "182: loss: 3.305154323577881\n",
            "183: loss: 4.0023274421691895\n",
            "184: loss: 3.9392342567443848\n",
            "185: loss: 4.0493083000183105\n",
            "186: loss: 3.1283819675445557\n",
            "187: loss: 3.718977451324463\n",
            "188: loss: 3.6858527660369873\n",
            "189: loss: 3.811516761779785\n",
            "190: loss: 2.711143970489502\n",
            "191: loss: 2.7761428356170654\n",
            "192: loss: 5.129826545715332\n",
            "193: loss: 3.798415184020996\n",
            "194: loss: 2.8574752807617188\n",
            "195: loss: 2.517055034637451\n",
            "196: loss: 3.6690587997436523\n",
            "197: loss: 2.7963733673095703\n",
            "198: loss: 5.04168701171875\n",
            "199: loss: 3.7538340091705322\n",
            "200: loss: 3.1954634189605713\n",
            "200: valid loss 2.672654867172241\n",
            "201: loss: 3.938833475112915\n",
            "202: loss: 2.2804007530212402\n",
            "203: loss: 2.9060604572296143\n",
            "204: loss: 3.358248472213745\n",
            "205: loss: 4.000835418701172\n",
            "206: loss: 3.9835970401763916\n",
            "207: loss: 4.861603260040283\n",
            "208: loss: 3.010981559753418\n",
            "209: loss: 3.0274980068206787\n",
            "210: loss: 3.7854485511779785\n",
            "211: loss: 5.348038673400879\n",
            "212: loss: 2.4158174991607666\n",
            "213: loss: 2.3764140605926514\n",
            "214: loss: 5.568849563598633\n",
            "215: loss: 5.062939167022705\n",
            "216: loss: 3.5975847244262695\n",
            "217: loss: 1.9735238552093506\n",
            "218: loss: 3.0455410480499268\n",
            "219: loss: 3.0600852966308594\n",
            "220: loss: 1.7105385065078735\n",
            "221: loss: 2.041619062423706\n",
            "222: loss: 2.7813313007354736\n",
            "223: loss: 3.4998953342437744\n",
            "224: loss: 2.199092149734497\n",
            "225: loss: 2.1976327896118164\n",
            "226: loss: 3.23608660697937\n",
            "227: loss: 2.798902988433838\n",
            "228: loss: 4.967743873596191\n",
            "229: loss: 3.563983917236328\n",
            "230: loss: 2.5824742317199707\n",
            "231: loss: 3.250448226928711\n",
            "232: loss: 3.980307102203369\n",
            "233: loss: 3.3716318607330322\n",
            "234: loss: 2.1092820167541504\n",
            "235: loss: 4.3450798988342285\n",
            "236: loss: 2.9500396251678467\n",
            "237: loss: 2.383422374725342\n",
            "238: loss: 4.156944751739502\n",
            "239: loss: 1.7663941383361816\n",
            "240: loss: 5.12321662902832\n",
            "241: loss: 3.4547643661499023\n",
            "242: loss: 2.7932348251342773\n",
            "243: loss: 3.9492850303649902\n",
            "244: loss: 3.2278764247894287\n",
            "245: loss: 4.091939449310303\n",
            "246: loss: 4.32229471206665\n",
            "247: loss: 4.081418991088867\n",
            "248: loss: 3.344590187072754\n",
            "249: loss: 3.702165126800537\n",
            "250: loss: 2.59597110748291\n",
            "251: loss: 4.052607536315918\n",
            "252: loss: 3.1400604248046875\n",
            "253: loss: 5.1511945724487305\n",
            "254: loss: 3.550908327102661\n",
            "255: loss: 2.2632644176483154\n",
            "256: loss: 3.5918984413146973\n",
            "257: loss: 3.3822648525238037\n",
            "258: loss: 3.154252052307129\n",
            "259: loss: 3.772869348526001\n",
            "260: loss: 2.696134090423584\n",
            "261: loss: 2.3007543087005615\n",
            "262: loss: 2.8377685546875\n",
            "263: loss: 3.6563382148742676\n",
            "264: loss: 3.808483362197876\n",
            "265: loss: 3.459498405456543\n",
            "266: loss: 3.378288745880127\n",
            "267: loss: 3.3718838691711426\n",
            "268: loss: 2.823511838912964\n",
            "269: loss: 4.0828680992126465\n",
            "270: loss: 3.1676025390625\n",
            "271: loss: 3.7163467407226562\n",
            "272: loss: 3.1986629962921143\n",
            "273: loss: 2.904474973678589\n",
            "274: loss: 1.816519021987915\n",
            "275: loss: 2.411349296569824\n",
            "276: loss: 3.5194363594055176\n",
            "277: loss: 4.230510711669922\n",
            "278: loss: 1.7121169567108154\n",
            "279: loss: 3.34657883644104\n",
            "280: loss: 2.3797945976257324\n",
            "281: loss: 2.5378921031951904\n",
            "282: loss: 2.646710157394409\n",
            "283: loss: 3.7734405994415283\n",
            "284: loss: 4.539144515991211\n",
            "285: loss: 3.550973653793335\n",
            "286: loss: 2.6558127403259277\n",
            "287: loss: 2.7779128551483154\n",
            "288: loss: 2.765700340270996\n",
            "289: loss: 4.03813362121582\n",
            "290: loss: 2.06777024269104\n",
            "291: loss: 3.1727802753448486\n",
            "292: loss: 1.946112871170044\n",
            "293: loss: 2.224174976348877\n",
            "294: loss: 5.835139751434326\n",
            "295: loss: 2.5537912845611572\n",
            "296: loss: 2.088162899017334\n",
            "297: loss: 3.0947768688201904\n",
            "298: loss: 3.9393646717071533\n",
            "299: loss: 2.490703582763672\n",
            "300: loss: 3.2154970169067383\n",
            "300: valid loss 3.577949047088623\n",
            "301: loss: 4.09451150894165\n",
            "302: loss: 3.2480926513671875\n",
            "303: loss: 2.4830780029296875\n",
            "304: loss: 3.184631109237671\n",
            "305: loss: 2.781986951828003\n",
            "306: loss: 3.2187957763671875\n",
            "307: loss: 3.3625776767730713\n",
            "308: loss: 3.381523609161377\n",
            "309: loss: 2.2431137561798096\n",
            "310: loss: 2.9578232765197754\n",
            "311: loss: 2.5556516647338867\n",
            "312: loss: 4.366853713989258\n",
            "313: loss: 2.9842634201049805\n",
            "314: loss: 4.575014114379883\n",
            "315: loss: 2.1964995861053467\n",
            "316: loss: 2.393810749053955\n",
            "317: loss: 6.075698375701904\n",
            "318: loss: 1.5917463302612305\n",
            "319: loss: 3.2215068340301514\n",
            "320: loss: 2.883424997329712\n",
            "321: loss: 2.661015272140503\n",
            "322: loss: 4.109929084777832\n",
            "323: loss: 2.4184420108795166\n",
            "324: loss: 3.4644906520843506\n",
            "325: loss: 3.059539556503296\n",
            "326: loss: 3.1503868103027344\n",
            "327: loss: 3.1904830932617188\n",
            "328: loss: 1.556504249572754\n",
            "329: loss: 2.4455902576446533\n",
            "330: loss: 4.634496688842773\n",
            "331: loss: 1.6626161336898804\n",
            "332: loss: 3.529869318008423\n",
            "333: loss: 3.6979122161865234\n",
            "334: loss: 3.8547017574310303\n",
            "335: loss: 4.5517578125\n",
            "336: loss: 3.1101038455963135\n",
            "337: loss: 3.46221661567688\n",
            "338: loss: 4.52696418762207\n",
            "339: loss: 3.601180076599121\n",
            "340: loss: 3.013132095336914\n",
            "341: loss: 3.032773017883301\n",
            "342: loss: 3.9409232139587402\n",
            "343: loss: 5.134700775146484\n",
            "344: loss: 2.3168208599090576\n",
            "345: loss: 2.0978658199310303\n",
            "346: loss: 3.2748069763183594\n",
            "347: loss: 2.07615065574646\n",
            "348: loss: 2.790142774581909\n",
            "349: loss: 2.023486375808716\n",
            "350: loss: 3.020190954208374\n",
            "351: loss: 3.363018035888672\n",
            "352: loss: 3.003386974334717\n",
            "353: loss: 2.6499202251434326\n",
            "354: loss: 3.2982680797576904\n",
            "355: loss: 4.25799560546875\n",
            "356: loss: 3.702066659927368\n",
            "357: loss: 2.605394124984741\n",
            "358: loss: 2.3880105018615723\n",
            "359: loss: 2.373379945755005\n",
            "360: loss: 3.3541457653045654\n",
            "361: loss: 4.762452125549316\n",
            "362: loss: 2.872387409210205\n",
            "363: loss: 2.9297714233398438\n",
            "364: loss: 2.3200299739837646\n",
            "365: loss: 1.7938928604125977\n",
            "366: loss: 4.407459735870361\n",
            "367: loss: 2.0376152992248535\n",
            "368: loss: 2.7205984592437744\n",
            "369: loss: 4.864945411682129\n",
            "370: loss: 4.066407203674316\n",
            "371: loss: 3.1050384044647217\n",
            "372: loss: 4.5417866706848145\n",
            "373: loss: 4.8433003425598145\n",
            "374: loss: 4.518158435821533\n",
            "375: loss: 3.6062917709350586\n",
            "376: loss: 3.386725425720215\n",
            "377: loss: 2.0785608291625977\n",
            "378: loss: 3.565791368484497\n",
            "379: loss: 2.3701353073120117\n",
            "380: loss: 2.6155529022216797\n",
            "381: loss: 2.595327138900757\n",
            "382: loss: 2.9573183059692383\n",
            "383: loss: 3.7079570293426514\n",
            "384: loss: 2.425318717956543\n",
            "385: loss: 2.515458583831787\n",
            "386: loss: 3.6786277294158936\n",
            "387: loss: 3.3268556594848633\n",
            "388: loss: 2.9305198192596436\n",
            "389: loss: 3.046499490737915\n",
            "390: loss: 2.7607035636901855\n",
            "391: loss: 3.774524211883545\n",
            "392: loss: 2.6073102951049805\n",
            "393: loss: 2.1738507747650146\n",
            "394: loss: 3.791842222213745\n",
            "395: loss: 5.11150598526001\n",
            "396: loss: 3.0518031120300293\n",
            "397: loss: 3.5776288509368896\n",
            "398: loss: 2.8081464767456055\n",
            "399: loss: 4.073093891143799\n",
            "400: loss: 3.2204697132110596\n",
            "400: valid loss 2.4448893070220947\n",
            "401: loss: 3.0393149852752686\n",
            "402: loss: 2.694305658340454\n",
            "403: loss: 2.9569785594940186\n",
            "404: loss: 3.9321041107177734\n",
            "405: loss: 2.406693696975708\n",
            "406: loss: 2.71213436126709\n",
            "407: loss: 3.077946901321411\n",
            "408: loss: 2.134211778640747\n",
            "409: loss: 2.8390355110168457\n",
            "410: loss: 3.4392178058624268\n",
            "411: loss: 2.69711971282959\n",
            "412: loss: 2.292283535003662\n",
            "413: loss: 3.9366188049316406\n",
            "414: loss: 3.2873482704162598\n",
            "415: loss: 2.306086778640747\n",
            "416: loss: 2.3488049507141113\n",
            "417: loss: 2.2153639793395996\n",
            "418: loss: 2.5413570404052734\n",
            "419: loss: 2.6585373878479004\n",
            "420: loss: 4.158815860748291\n",
            "421: loss: 3.370366096496582\n",
            "422: loss: 3.151865005493164\n",
            "423: loss: 4.181602478027344\n",
            "424: loss: 3.0728182792663574\n",
            "425: loss: 2.493133544921875\n",
            "426: loss: 2.725687026977539\n",
            "427: loss: 2.2705600261688232\n",
            "428: loss: 3.2365517616271973\n",
            "429: loss: 2.8848202228546143\n",
            "430: loss: 3.3324942588806152\n",
            "431: loss: 3.0512218475341797\n",
            "432: loss: 2.527906894683838\n",
            "433: loss: 2.504925489425659\n",
            "434: loss: 2.7435548305511475\n",
            "435: loss: 2.999894380569458\n",
            "436: loss: 4.344742774963379\n",
            "437: loss: 3.6248531341552734\n",
            "438: loss: 3.6357638835906982\n",
            "439: loss: 2.9594802856445312\n",
            "440: loss: 4.199413776397705\n",
            "441: loss: 3.267735719680786\n",
            "442: loss: 3.4768147468566895\n",
            "443: loss: 4.095769882202148\n",
            "444: loss: 3.43988299369812\n",
            "445: loss: 3.0783612728118896\n",
            "446: loss: 2.81795597076416\n",
            "447: loss: 3.4083945751190186\n",
            "448: loss: 3.376685619354248\n",
            "449: loss: 3.6393632888793945\n",
            "450: loss: 2.133258104324341\n",
            "451: loss: 3.114577054977417\n",
            "452: loss: 2.683213472366333\n",
            "453: loss: 2.560516119003296\n",
            "454: loss: 4.727576732635498\n",
            "455: loss: 2.732194185256958\n",
            "456: loss: 1.6410562992095947\n",
            "457: loss: 3.286550760269165\n",
            "458: loss: 4.042823314666748\n",
            "459: loss: 3.2378735542297363\n",
            "460: loss: 2.9295012950897217\n",
            "461: loss: 3.300698757171631\n",
            "462: loss: 2.7430636882781982\n",
            "463: loss: 3.614656925201416\n",
            "464: loss: 2.402357578277588\n",
            "465: loss: 1.9123550653457642\n",
            "466: loss: 1.8379710912704468\n",
            "467: loss: 4.161538124084473\n",
            "468: loss: 2.7740986347198486\n",
            "469: loss: 3.027843713760376\n",
            "470: loss: 2.592729330062866\n",
            "471: loss: 2.0832536220550537\n",
            "472: loss: 2.321037769317627\n",
            "473: loss: 2.743943691253662\n",
            "474: loss: 2.863887310028076\n",
            "475: loss: 4.156899452209473\n",
            "476: loss: 3.2734673023223877\n",
            "477: loss: 2.461475372314453\n",
            "478: loss: 1.6162961721420288\n",
            "479: loss: 2.0610368251800537\n",
            "480: loss: 2.077105760574341\n",
            "481: loss: 4.0384345054626465\n",
            "482: loss: 2.5808520317077637\n",
            "483: loss: 3.5656540393829346\n",
            "484: loss: 2.0416975021362305\n",
            "485: loss: 3.9623069763183594\n",
            "486: loss: 2.584773063659668\n",
            "487: loss: 3.429361581802368\n",
            "488: loss: 3.2214365005493164\n",
            "489: loss: 2.157101631164551\n",
            "490: loss: 2.501455783843994\n",
            "491: loss: 3.4098265171051025\n",
            "492: loss: 4.367472171783447\n",
            "493: loss: 4.415870189666748\n",
            "494: loss: 2.5346879959106445\n",
            "495: loss: 1.878053069114685\n",
            "496: loss: 2.2301137447357178\n",
            "497: loss: 2.668699264526367\n",
            "498: loss: 3.307914972305298\n",
            "499: loss: 2.251884937286377\n",
            "500: loss: 3.6919283866882324\n",
            "500: valid loss 1.918553113937378\n",
            "501: loss: 3.2425670623779297\n",
            "502: loss: 3.2654805183410645\n",
            "503: loss: 4.770808696746826\n",
            "504: loss: 2.6390161514282227\n",
            "505: loss: 3.8128161430358887\n",
            "506: loss: 3.1041183471679688\n",
            "507: loss: 3.026628255844116\n",
            "508: loss: 2.1366872787475586\n",
            "509: loss: 3.517521858215332\n",
            "510: loss: 3.1921277046203613\n",
            "511: loss: 2.969904899597168\n",
            "512: loss: 2.7593116760253906\n",
            "513: loss: 2.4144303798675537\n",
            "514: loss: 3.2206318378448486\n",
            "515: loss: 2.664259910583496\n",
            "516: loss: 3.3883302211761475\n",
            "517: loss: 2.6432647705078125\n",
            "518: loss: 3.306957483291626\n",
            "519: loss: 3.2432031631469727\n",
            "520: loss: 3.0358846187591553\n",
            "521: loss: 2.236567735671997\n",
            "522: loss: 3.1817221641540527\n",
            "523: loss: 4.5208258628845215\n",
            "524: loss: 2.7660305500030518\n",
            "525: loss: 3.246859312057495\n",
            "526: loss: 2.6675593852996826\n",
            "527: loss: 2.995195150375366\n",
            "528: loss: 2.4465787410736084\n",
            "529: loss: 2.5033297538757324\n",
            "530: loss: 4.036996841430664\n",
            "531: loss: 3.3609554767608643\n",
            "532: loss: 1.648195505142212\n",
            "533: loss: 2.2983806133270264\n",
            "534: loss: 3.189020872116089\n",
            "535: loss: 2.7750790119171143\n",
            "536: loss: 2.1909053325653076\n",
            "537: loss: 1.7156040668487549\n",
            "538: loss: 3.0652029514312744\n",
            "539: loss: 3.6364245414733887\n",
            "540: loss: 2.060016632080078\n",
            "541: loss: 3.733494997024536\n",
            "542: loss: 2.8900675773620605\n",
            "543: loss: 2.107334613800049\n",
            "544: loss: 3.340892791748047\n",
            "545: loss: 3.175337553024292\n",
            "546: loss: 4.783037185668945\n",
            "547: loss: 1.696775197982788\n",
            "548: loss: 3.481330156326294\n",
            "549: loss: 3.0979127883911133\n",
            "550: loss: 2.183377504348755\n",
            "551: loss: 3.2101492881774902\n",
            "552: loss: 2.095712900161743\n",
            "553: loss: 3.5599887371063232\n",
            "554: loss: 2.7196033000946045\n",
            "555: loss: 2.5922110080718994\n",
            "556: loss: 2.0579657554626465\n",
            "557: loss: 3.012544870376587\n",
            "558: loss: 2.1520259380340576\n",
            "559: loss: 3.115224599838257\n",
            "560: loss: 2.284459114074707\n",
            "561: loss: 2.4260308742523193\n",
            "562: loss: 2.278463125228882\n",
            "563: loss: 2.7700138092041016\n",
            "564: loss: 2.944622039794922\n",
            "565: loss: 2.87656307220459\n",
            "566: loss: 2.1346514225006104\n",
            "567: loss: 2.8049795627593994\n",
            "568: loss: 4.2727251052856445\n",
            "569: loss: 2.3226444721221924\n",
            "570: loss: 2.7066924571990967\n",
            "571: loss: 3.7698745727539062\n",
            "572: loss: 3.7127339839935303\n",
            "573: loss: 2.0796000957489014\n",
            "574: loss: 3.70831298828125\n",
            "575: loss: 1.890816569328308\n",
            "576: loss: 3.8429267406463623\n",
            "577: loss: 3.048373222351074\n",
            "578: loss: 2.360567331314087\n",
            "579: loss: 2.47348690032959\n",
            "580: loss: 4.027107238769531\n",
            "581: loss: 2.864957571029663\n",
            "582: loss: 2.6087515354156494\n",
            "583: loss: 2.8924808502197266\n",
            "584: loss: 2.208123207092285\n",
            "585: loss: 2.0100347995758057\n",
            "586: loss: 2.604583263397217\n",
            "587: loss: 3.366990327835083\n",
            "588: loss: 2.389394521713257\n",
            "589: loss: 1.4803963899612427\n",
            "590: loss: 3.0731353759765625\n",
            "591: loss: 3.4747610092163086\n",
            "592: loss: 2.2600395679473877\n",
            "593: loss: 3.203263282775879\n",
            "594: loss: 4.275605201721191\n",
            "595: loss: 2.1793627738952637\n",
            "596: loss: 2.1482768058776855\n",
            "597: loss: 3.7521042823791504\n",
            "598: loss: 4.180765151977539\n",
            "599: loss: 4.092630386352539\n",
            "600: loss: 4.396822929382324\n",
            "600: valid loss 3.1054282188415527\n",
            "601: loss: 2.3585610389709473\n",
            "602: loss: 3.2306973934173584\n",
            "603: loss: 2.4940717220306396\n",
            "604: loss: 2.5989511013031006\n",
            "605: loss: 1.6197646856307983\n",
            "606: loss: 2.2688210010528564\n",
            "607: loss: 3.9972915649414062\n",
            "608: loss: 3.8981072902679443\n",
            "609: loss: 2.8412437438964844\n",
            "610: loss: 2.59938645362854\n",
            "611: loss: 2.7147374153137207\n",
            "612: loss: 3.1625125408172607\n",
            "613: loss: 1.6467063426971436\n",
            "614: loss: 2.7817938327789307\n",
            "615: loss: 4.063793182373047\n",
            "616: loss: 2.858102560043335\n",
            "617: loss: 2.3292737007141113\n",
            "618: loss: 2.9356296062469482\n",
            "619: loss: 4.598741054534912\n",
            "620: loss: 2.877274513244629\n",
            "621: loss: 3.193347692489624\n",
            "622: loss: 1.7585649490356445\n",
            "623: loss: 3.5163841247558594\n",
            "624: loss: 2.4775257110595703\n",
            "625: loss: 4.092735290527344\n",
            "626: loss: 2.58660626411438\n",
            "627: loss: 3.6198182106018066\n",
            "628: loss: 2.9030935764312744\n",
            "629: loss: 4.212423801422119\n",
            "630: loss: 2.533655881881714\n",
            "631: loss: 3.1972498893737793\n",
            "632: loss: 4.296469211578369\n",
            "633: loss: 2.8326900005340576\n",
            "634: loss: 2.936678647994995\n",
            "635: loss: 3.3144278526306152\n",
            "636: loss: 2.2343103885650635\n",
            "637: loss: 2.8307390213012695\n",
            "638: loss: 1.5917489528656006\n",
            "639: loss: 3.8545947074890137\n",
            "640: loss: 2.92700457572937\n",
            "641: loss: 3.4616944789886475\n",
            "642: loss: 2.415499210357666\n",
            "643: loss: 2.2834243774414062\n",
            "644: loss: 2.9450504779815674\n",
            "645: loss: 3.217099189758301\n",
            "646: loss: 3.4854202270507812\n",
            "647: loss: 2.684114933013916\n",
            "648: loss: 3.16182541847229\n",
            "649: loss: 2.5642993450164795\n",
            "650: loss: 2.5596323013305664\n",
            "651: loss: 2.782740592956543\n",
            "652: loss: 3.065469741821289\n",
            "653: loss: 2.791973829269409\n",
            "654: loss: 2.1568245887756348\n",
            "655: loss: 2.6257219314575195\n",
            "656: loss: 2.1912283897399902\n",
            "657: loss: 2.153980255126953\n",
            "658: loss: 4.352012634277344\n",
            "659: loss: 2.6089072227478027\n",
            "660: loss: 3.450948715209961\n",
            "661: loss: 2.7814712524414062\n",
            "662: loss: 2.5830345153808594\n",
            "663: loss: 3.5308077335357666\n",
            "664: loss: 2.7695484161376953\n",
            "665: loss: 2.5942986011505127\n",
            "666: loss: 2.856377124786377\n",
            "667: loss: 1.9369906187057495\n",
            "668: loss: 3.1019489765167236\n",
            "669: loss: 2.746084451675415\n",
            "670: loss: 2.94753098487854\n",
            "671: loss: 2.56598162651062\n",
            "672: loss: 2.124399185180664\n",
            "673: loss: 1.798727035522461\n",
            "674: loss: 3.5058352947235107\n",
            "675: loss: 2.7259368896484375\n",
            "676: loss: 3.1166982650756836\n",
            "677: loss: 2.9378445148468018\n",
            "678: loss: 2.328871965408325\n",
            "679: loss: 3.5860531330108643\n",
            "680: loss: 2.8179919719696045\n",
            "681: loss: 1.4399486780166626\n",
            "682: loss: 2.93754506111145\n",
            "683: loss: 2.532233238220215\n",
            "684: loss: 1.7397907972335815\n",
            "685: loss: 2.8296563625335693\n",
            "686: loss: 2.939519166946411\n",
            "687: loss: 2.0095055103302\n",
            "688: loss: 3.4424848556518555\n",
            "689: loss: 2.563032865524292\n",
            "690: loss: 2.7207913398742676\n",
            "691: loss: 3.0801539421081543\n",
            "692: loss: 1.600219964981079\n",
            "693: loss: 3.6264209747314453\n",
            "694: loss: 2.9958114624023438\n",
            "695: loss: 2.4835994243621826\n",
            "696: loss: 3.2280492782592773\n",
            "697: loss: 3.525369882583618\n",
            "698: loss: 4.260843276977539\n",
            "699: loss: 2.508929967880249\n",
            "700: loss: 3.6963160037994385\n",
            "700: valid loss 2.6665852069854736\n",
            "701: loss: 2.5090293884277344\n",
            "702: loss: 3.0543746948242188\n",
            "703: loss: 1.8351874351501465\n",
            "704: loss: 3.1594841480255127\n",
            "705: loss: 2.892226457595825\n",
            "706: loss: 3.384106397628784\n",
            "707: loss: 3.4289422035217285\n",
            "708: loss: 2.721756935119629\n",
            "709: loss: 2.38093638420105\n",
            "710: loss: 5.131703853607178\n",
            "711: loss: 3.615293264389038\n",
            "712: loss: 3.3615121841430664\n",
            "713: loss: 3.521470308303833\n",
            "714: loss: 2.4075632095336914\n",
            "715: loss: 3.1787238121032715\n",
            "716: loss: 2.3651010990142822\n",
            "717: loss: 3.0488831996917725\n",
            "718: loss: 2.6396381855010986\n",
            "719: loss: 1.7827951908111572\n",
            "720: loss: 2.6251938343048096\n",
            "721: loss: 3.8379204273223877\n",
            "722: loss: 3.3101375102996826\n",
            "723: loss: 3.516942262649536\n",
            "724: loss: 2.9953622817993164\n",
            "725: loss: 2.6918344497680664\n",
            "726: loss: 3.4953114986419678\n",
            "727: loss: 2.207697868347168\n",
            "728: loss: 2.764362335205078\n",
            "729: loss: 3.7082440853118896\n",
            "730: loss: 3.806931972503662\n",
            "731: loss: 3.3530361652374268\n",
            "732: loss: 3.1677160263061523\n",
            "733: loss: 2.5898828506469727\n",
            "734: loss: 2.356569766998291\n",
            "735: loss: 1.7963604927062988\n",
            "736: loss: 3.1192917823791504\n",
            "737: loss: 3.4110329151153564\n",
            "738: loss: 2.7743778228759766\n",
            "739: loss: 2.1046247482299805\n",
            "740: loss: 2.2446513175964355\n",
            "741: loss: 2.688102960586548\n",
            "742: loss: 2.557633399963379\n",
            "743: loss: 2.2630136013031006\n",
            "744: loss: 1.9620459079742432\n",
            "745: loss: 2.6038482189178467\n",
            "746: loss: 4.1712117195129395\n",
            "747: loss: 1.986254334449768\n",
            "748: loss: 2.8377158641815186\n",
            "749: loss: 3.4291718006134033\n",
            "750: loss: 3.09926438331604\n",
            "751: loss: 3.507979154586792\n",
            "752: loss: 2.5156071186065674\n",
            "753: loss: 2.5726161003112793\n",
            "754: loss: 2.8212153911590576\n",
            "755: loss: 3.3308966159820557\n",
            "756: loss: 3.1208667755126953\n",
            "757: loss: 2.1087329387664795\n",
            "758: loss: 3.037010431289673\n",
            "759: loss: 2.140446662902832\n",
            "760: loss: 2.711198091506958\n",
            "761: loss: 1.4168726205825806\n",
            "762: loss: 2.1252222061157227\n",
            "763: loss: 2.9147450923919678\n",
            "764: loss: 2.476058006286621\n",
            "765: loss: 3.0235443115234375\n",
            "766: loss: 3.4320425987243652\n",
            "767: loss: 3.6129519939422607\n",
            "768: loss: 1.9102798700332642\n",
            "769: loss: 2.886467218399048\n",
            "770: loss: 3.2798867225646973\n",
            "771: loss: 2.4810028076171875\n",
            "772: loss: 2.505661964416504\n",
            "773: loss: 3.2061870098114014\n",
            "774: loss: 2.525209426879883\n",
            "775: loss: 2.959754228591919\n",
            "776: loss: 2.6962273120880127\n",
            "777: loss: 2.7415828704833984\n",
            "778: loss: 2.20383358001709\n",
            "779: loss: 3.4089150428771973\n",
            "780: loss: 2.5379254817962646\n",
            "781: loss: 2.2697134017944336\n",
            "782: loss: 3.6752209663391113\n",
            "783: loss: 1.8782399892807007\n",
            "784: loss: 2.2274205684661865\n",
            "785: loss: 3.740466356277466\n",
            "786: loss: 4.01135778427124\n",
            "787: loss: 2.7689871788024902\n",
            "788: loss: 3.3724257946014404\n",
            "789: loss: 2.596421718597412\n",
            "790: loss: 3.4096407890319824\n",
            "791: loss: 3.4609339237213135\n",
            "792: loss: 3.260486364364624\n",
            "793: loss: 3.0317835807800293\n",
            "794: loss: 2.8379299640655518\n",
            "795: loss: 5.149363040924072\n",
            "796: loss: 3.036634683609009\n",
            "797: loss: 3.0202155113220215\n",
            "798: loss: 5.1592936515808105\n",
            "799: loss: 3.1715948581695557\n",
            "800: loss: 2.9006917476654053\n",
            "800: valid loss 2.8487701416015625\n",
            "801: loss: 3.1787302494049072\n",
            "802: loss: 2.42946457862854\n",
            "803: loss: 2.585273265838623\n",
            "804: loss: 3.2046754360198975\n",
            "805: loss: 2.6495840549468994\n",
            "806: loss: 4.117666721343994\n",
            "807: loss: 3.0186538696289062\n",
            "808: loss: 3.4392082691192627\n",
            "809: loss: 2.337733745574951\n",
            "810: loss: 3.8391127586364746\n",
            "811: loss: 3.2428247928619385\n",
            "812: loss: 2.9528446197509766\n",
            "813: loss: 3.511103868484497\n",
            "814: loss: 1.9058305025100708\n",
            "815: loss: 2.617950439453125\n",
            "816: loss: 2.0635852813720703\n",
            "817: loss: 1.870074987411499\n",
            "818: loss: 2.541098117828369\n",
            "819: loss: 4.2056121826171875\n",
            "820: loss: 2.7369205951690674\n",
            "821: loss: 2.2776482105255127\n",
            "822: loss: 3.3819046020507812\n",
            "823: loss: 2.9134936332702637\n",
            "824: loss: 1.6982934474945068\n",
            "825: loss: 3.293750524520874\n",
            "826: loss: 3.067567825317383\n",
            "827: loss: 3.2708680629730225\n",
            "828: loss: 3.1861412525177\n",
            "829: loss: 2.495265007019043\n",
            "830: loss: 2.8535823822021484\n",
            "831: loss: 3.0914039611816406\n",
            "832: loss: 3.22529935836792\n",
            "833: loss: 4.040653228759766\n",
            "834: loss: 2.6355202198028564\n",
            "835: loss: 2.5738046169281006\n",
            "836: loss: 2.6671431064605713\n",
            "837: loss: 2.485139846801758\n",
            "838: loss: 1.94632089138031\n",
            "839: loss: 2.543930768966675\n",
            "840: loss: 3.763211250305176\n",
            "841: loss: 4.240978240966797\n",
            "842: loss: 1.8167139291763306\n",
            "843: loss: 2.479207754135132\n",
            "844: loss: 4.069870471954346\n",
            "845: loss: 2.4486308097839355\n",
            "846: loss: 2.595930814743042\n",
            "847: loss: 1.788219928741455\n",
            "848: loss: 2.2700228691101074\n",
            "849: loss: 2.3874685764312744\n",
            "850: loss: 2.9104931354522705\n",
            "851: loss: 2.3810839653015137\n",
            "852: loss: 2.5224928855895996\n",
            "853: loss: 2.0449206829071045\n",
            "854: loss: 3.169525623321533\n",
            "855: loss: 3.578709125518799\n",
            "856: loss: 2.6624577045440674\n",
            "857: loss: 1.657954216003418\n",
            "858: loss: 3.534792900085449\n",
            "859: loss: 4.0370354652404785\n",
            "860: loss: 2.7052419185638428\n",
            "861: loss: 2.4208555221557617\n",
            "862: loss: 3.773639440536499\n",
            "863: loss: 2.004434823989868\n",
            "864: loss: 2.9518814086914062\n",
            "865: loss: 4.005573749542236\n",
            "866: loss: 3.941922426223755\n",
            "867: loss: 3.3893916606903076\n",
            "868: loss: 2.537607431411743\n",
            "869: loss: 1.872356653213501\n",
            "870: loss: 3.032125949859619\n",
            "871: loss: 3.0139269828796387\n",
            "872: loss: 3.404773235321045\n",
            "873: loss: 2.880850076675415\n",
            "874: loss: 2.9269349575042725\n",
            "875: loss: 2.4394047260284424\n",
            "876: loss: 2.1527557373046875\n",
            "877: loss: 3.1439623832702637\n",
            "878: loss: 2.443774938583374\n",
            "879: loss: 2.86257004737854\n",
            "880: loss: 2.7660133838653564\n",
            "881: loss: 2.659153938293457\n",
            "882: loss: 2.6939737796783447\n",
            "883: loss: 2.2621495723724365\n",
            "884: loss: 1.8460068702697754\n",
            "885: loss: 2.5967555046081543\n",
            "886: loss: 2.6959285736083984\n",
            "887: loss: 2.2829666137695312\n",
            "888: loss: 2.2609949111938477\n",
            "889: loss: 3.810818672180176\n",
            "890: loss: 4.5608062744140625\n",
            "891: loss: 2.1802122592926025\n",
            "892: loss: 3.2204439640045166\n",
            "893: loss: 1.9726628065109253\n",
            "894: loss: 3.466728687286377\n",
            "895: loss: 2.302180767059326\n",
            "896: loss: 2.614518642425537\n",
            "897: loss: 1.4107334613800049\n",
            "898: loss: 2.4344441890716553\n",
            "899: loss: 2.6290647983551025\n",
            "900: loss: 3.517465114593506\n",
            "900: valid loss 3.129300117492676\n",
            "901: loss: 1.8388069868087769\n",
            "902: loss: 3.528393268585205\n",
            "903: loss: 2.736222743988037\n",
            "904: loss: 4.473569869995117\n",
            "905: loss: 3.1894311904907227\n",
            "906: loss: 3.8499324321746826\n",
            "907: loss: 2.8384203910827637\n",
            "908: loss: 3.612391948699951\n",
            "909: loss: 1.8778679370880127\n",
            "910: loss: 2.4166812896728516\n",
            "911: loss: 2.570906639099121\n",
            "912: loss: 1.8310315608978271\n",
            "913: loss: 3.0216240882873535\n",
            "914: loss: 3.0967063903808594\n",
            "915: loss: 2.780365467071533\n",
            "916: loss: 2.338047742843628\n",
            "917: loss: 3.339953899383545\n",
            "918: loss: 3.1572165489196777\n",
            "919: loss: 2.8483474254608154\n",
            "920: loss: 2.739473581314087\n",
            "921: loss: 4.814376354217529\n",
            "922: loss: 3.516789674758911\n",
            "923: loss: 3.470327854156494\n",
            "924: loss: 3.38362717628479\n",
            "925: loss: 2.179075241088867\n",
            "926: loss: 2.678190231323242\n",
            "927: loss: 3.0194921493530273\n",
            "928: loss: 3.5833678245544434\n",
            "929: loss: 1.944252371788025\n",
            "930: loss: 4.000269412994385\n",
            "931: loss: 2.893672227859497\n",
            "932: loss: 2.6440188884735107\n",
            "933: loss: 2.64690899848938\n",
            "934: loss: 2.9357542991638184\n",
            "935: loss: 3.3940229415893555\n",
            "936: loss: 3.8947417736053467\n",
            "937: loss: 1.955628514289856\n",
            "938: loss: 2.6130828857421875\n",
            "939: loss: 2.4565341472625732\n",
            "940: loss: 2.8620707988739014\n",
            "941: loss: 2.61200213432312\n",
            "942: loss: 2.2449028491973877\n",
            "943: loss: 1.902121901512146\n",
            "944: loss: 2.9489572048187256\n",
            "945: loss: 1.8274065256118774\n",
            "946: loss: 1.8807677030563354\n",
            "947: loss: 2.0506591796875\n",
            "948: loss: 2.425060510635376\n",
            "949: loss: 1.905439019203186\n",
            "950: loss: 2.6315832138061523\n",
            "951: loss: 2.1946592330932617\n",
            "952: loss: 2.199286460876465\n",
            "953: loss: 1.7255678176879883\n",
            "954: loss: 1.4656363725662231\n",
            "955: loss: 2.7909891605377197\n",
            "956: loss: 1.8715144395828247\n",
            "957: loss: 2.5839905738830566\n",
            "958: loss: 2.7896625995635986\n",
            "959: loss: 2.8366611003875732\n",
            "960: loss: 2.780810594558716\n",
            "961: loss: 2.508211135864258\n",
            "962: loss: 3.5826470851898193\n",
            "963: loss: 2.1422994136810303\n",
            "964: loss: 1.8918288946151733\n",
            "965: loss: 2.27050518989563\n",
            "966: loss: 2.3844494819641113\n",
            "967: loss: 3.3504436016082764\n",
            "968: loss: 3.8291544914245605\n",
            "969: loss: 2.9024853706359863\n",
            "970: loss: 2.6024372577667236\n",
            "971: loss: 2.6442437171936035\n",
            "972: loss: 2.859748363494873\n",
            "973: loss: 3.226641893386841\n",
            "974: loss: 3.3262689113616943\n",
            "975: loss: 3.680438756942749\n",
            "976: loss: 3.509047746658325\n",
            "977: loss: 3.069937229156494\n",
            "978: loss: 2.9431092739105225\n",
            "979: loss: 3.9120864868164062\n",
            "980: loss: 2.904700994491577\n",
            "981: loss: 3.043962240219116\n",
            "982: loss: 3.4643518924713135\n",
            "983: loss: 4.159729957580566\n",
            "984: loss: 2.08587908744812\n",
            "985: loss: 1.8985730409622192\n",
            "986: loss: 3.0640480518341064\n",
            "987: loss: 2.940077066421509\n",
            "988: loss: 4.114999294281006\n",
            "989: loss: 2.3868343830108643\n",
            "990: loss: 1.7002824544906616\n",
            "991: loss: 1.378230333328247\n",
            "992: loss: 1.7744923830032349\n",
            "993: loss: 2.4855072498321533\n",
            "994: loss: 3.281677722930908\n",
            "995: loss: 2.3678131103515625\n",
            "996: loss: 1.5419740676879883\n",
            "997: loss: 2.0967767238616943\n",
            "998: loss: 3.5568454265594482\n",
            "999: loss: 2.2241744995117188\n",
            "training complete\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "osQvXP6aGJEx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "\n",
        "import torch\n",
        "from audiolm_pytorch import HubertWithKmeans, SoundStream, CoarseTransformer, CoarseTransformerTrainer\n",
        "\n",
        "# wav2vec = HubertWithKmeans(\n",
        "#     checkpoint_path = '/content/drive/MyDrive/hubert_base_ls960.pt',\n",
        "#     kmeans_path = '/content/drive/MyDrive/hubert_base_ls960_L9_km500.bin'\n",
        "# )\n",
        "\n",
        "#soundstream = SoundStream.init_and_load_from('/path/to/trained/soundstream.pt')\n",
        "\n",
        "coarse_transformer = CoarseTransformer(\n",
        "    num_semantic_tokens = wav2vec.codebook_size,\n",
        "    codebook_size = 1024,\n",
        "    num_coarse_quantizers = 3,\n",
        "    dim = 1024,\n",
        "    depth = 6,\n",
        "    audio_text_condition = True,\n",
        "    has_condition = True\n",
        ").cuda()\n",
        "\n",
        "trainer = CoarseTransformerTrainer(\n",
        "    transformer = coarse_transformer,\n",
        "    codec = soundstream,\n",
        "    wav2vec = wav2vec,\n",
        "    audio_conditioner = quantizer,\n",
        "    folder = '/content/drive/MyDrive/ArtML_Final/recordings',\n",
        "    batch_size = 1,\n",
        "    data_max_length = 320 * 32,\n",
        "    num_train_steps = 1000\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbnOpVyqtSF5",
        "outputId": "c4b15415-314f-4a4d-b80a-1f8642532943"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training with dataset of 2850 samples and validating with randomly splitted 150 samples\n",
            "do you want to clear previous experiment checkpoints and results? (y/n) y\n",
            "0: loss: 97.36138916015625\n",
            "0: valid loss 217.82882690429688\n",
            "0: saving model to results\n",
            "1: loss: 175.84210205078125\n",
            "2: loss: 151.42623901367188\n",
            "3: loss: 75.79421997070312\n",
            "4: loss: 86.1459732055664\n",
            "5: loss: 91.30323028564453\n",
            "6: loss: 197.7296905517578\n",
            "7: loss: 121.2177505493164\n",
            "8: loss: 36.627708435058594\n",
            "9: loss: 62.315460205078125\n",
            "10: loss: 67.99581146240234\n",
            "11: loss: 67.14136505126953\n",
            "12: loss: 56.054569244384766\n",
            "13: loss: 192.08349609375\n",
            "14: loss: 155.24398803710938\n",
            "15: loss: 88.91699981689453\n",
            "16: loss: 95.12409210205078\n",
            "17: loss: 63.50566101074219\n",
            "18: loss: 55.24103546142578\n",
            "19: loss: 52.708641052246094\n",
            "20: loss: 74.2483901977539\n",
            "21: loss: 41.16132736206055\n",
            "22: loss: 52.91457748413086\n",
            "23: loss: 53.62237548828125\n",
            "24: loss: 47.7381706237793\n",
            "25: loss: 49.69729232788086\n",
            "26: loss: 29.14586639404297\n",
            "27: loss: 24.07536506652832\n",
            "28: loss: 53.902000427246094\n",
            "29: loss: 24.225963592529297\n",
            "30: loss: 36.79774856567383\n",
            "31: loss: 44.90795135498047\n",
            "32: loss: 49.627723693847656\n",
            "33: loss: 29.685302734375\n",
            "34: loss: 16.07732582092285\n",
            "35: loss: 40.672279357910156\n",
            "36: loss: 44.321651458740234\n",
            "37: loss: 31.252540588378906\n",
            "38: loss: 43.57529067993164\n",
            "39: loss: 13.997734069824219\n",
            "40: loss: 40.21993637084961\n",
            "41: loss: 36.74319076538086\n",
            "42: loss: 45.611236572265625\n",
            "43: loss: 28.908889770507812\n",
            "44: loss: 37.95344543457031\n",
            "45: loss: 31.496471405029297\n",
            "46: loss: 14.678122520446777\n",
            "47: loss: 33.66617202758789\n",
            "48: loss: 8.30182933807373\n",
            "49: loss: 11.001534461975098\n",
            "50: loss: 59.469974517822266\n",
            "51: loss: 31.621984481811523\n",
            "52: loss: 30.689029693603516\n",
            "53: loss: 13.622671127319336\n",
            "54: loss: 13.010997772216797\n",
            "55: loss: 19.996356964111328\n",
            "56: loss: 42.7762336730957\n",
            "57: loss: 39.17304992675781\n",
            "58: loss: 23.09107780456543\n",
            "59: loss: 18.531038284301758\n",
            "60: loss: 51.844791412353516\n",
            "61: loss: 25.25490951538086\n",
            "62: loss: 20.650569915771484\n",
            "63: loss: 21.32179832458496\n",
            "64: loss: 30.587818145751953\n",
            "65: loss: 36.90443420410156\n",
            "66: loss: 13.860651016235352\n",
            "67: loss: 30.609468460083008\n",
            "68: loss: 10.449316024780273\n",
            "69: loss: 5.828336715698242\n",
            "70: loss: 6.115220546722412\n",
            "71: loss: 10.541152000427246\n",
            "72: loss: 27.536590576171875\n",
            "73: loss: 30.85806655883789\n",
            "74: loss: 8.107527732849121\n",
            "75: loss: 19.400148391723633\n",
            "76: loss: 20.23406982421875\n",
            "77: loss: 23.277843475341797\n",
            "78: loss: 18.474464416503906\n",
            "79: loss: 8.590865135192871\n",
            "80: loss: 24.30675506591797\n",
            "81: loss: 16.4190616607666\n",
            "82: loss: 9.406275749206543\n",
            "83: loss: 8.55880069732666\n",
            "84: loss: 24.814115524291992\n",
            "85: loss: 15.475968360900879\n",
            "86: loss: 19.39067840576172\n",
            "87: loss: 30.538896560668945\n",
            "88: loss: 9.69827938079834\n",
            "89: loss: 13.936995506286621\n",
            "90: loss: 6.551235198974609\n",
            "91: loss: 21.91106605529785\n",
            "92: loss: 14.001053810119629\n",
            "93: loss: 4.0724406242370605\n",
            "94: loss: 5.301808834075928\n",
            "95: loss: 6.4186906814575195\n",
            "96: loss: 5.137075424194336\n",
            "97: loss: 23.346561431884766\n",
            "98: loss: 6.353279113769531\n",
            "99: loss: 29.532461166381836\n",
            "100: loss: 6.857723712921143\n",
            "100: valid loss 12.575470924377441\n",
            "101: loss: 17.16044044494629\n",
            "102: loss: 20.803558349609375\n",
            "103: loss: 4.808429718017578\n",
            "104: loss: 3.60650372505188\n",
            "105: loss: 5.663183689117432\n",
            "106: loss: 17.792627334594727\n",
            "107: loss: 34.552734375\n",
            "108: loss: 12.125540733337402\n",
            "109: loss: 28.227134704589844\n",
            "110: loss: 10.053199768066406\n",
            "111: loss: 15.56556510925293\n",
            "112: loss: 11.21003246307373\n",
            "113: loss: 12.606739044189453\n",
            "114: loss: 8.116436958312988\n",
            "115: loss: 8.180091857910156\n",
            "116: loss: 17.84699058532715\n",
            "117: loss: 18.262109756469727\n",
            "118: loss: 17.40475845336914\n",
            "119: loss: 24.210208892822266\n",
            "120: loss: 15.165160179138184\n",
            "121: loss: 10.350403785705566\n",
            "122: loss: 26.022947311401367\n",
            "123: loss: 21.672170639038086\n",
            "124: loss: 6.783661842346191\n",
            "125: loss: 12.43442153930664\n",
            "126: loss: 11.215340614318848\n",
            "127: loss: 20.27658462524414\n",
            "128: loss: 6.172219276428223\n",
            "129: loss: 18.15088653564453\n",
            "130: loss: 21.925065994262695\n",
            "131: loss: 27.433700561523438\n",
            "132: loss: 4.525673866271973\n",
            "133: loss: 5.474011421203613\n",
            "134: loss: 6.2135329246521\n",
            "135: loss: 6.607643127441406\n",
            "136: loss: 7.267475128173828\n",
            "137: loss: 8.506450653076172\n",
            "138: loss: 20.716419219970703\n",
            "139: loss: 21.836462020874023\n",
            "140: loss: 18.013803482055664\n",
            "141: loss: 11.828285217285156\n",
            "142: loss: 13.085431098937988\n",
            "143: loss: 21.195261001586914\n",
            "144: loss: 15.417139053344727\n",
            "145: loss: 14.711194038391113\n",
            "146: loss: 9.210509300231934\n",
            "147: loss: 12.684110641479492\n",
            "148: loss: 15.594383239746094\n",
            "149: loss: 11.92134952545166\n",
            "150: loss: 7.640054225921631\n",
            "151: loss: 20.741336822509766\n",
            "152: loss: 21.1173038482666\n",
            "153: loss: 20.10618782043457\n",
            "154: loss: 7.2820000648498535\n",
            "155: loss: 14.354451179504395\n",
            "156: loss: 15.523362159729004\n",
            "157: loss: 7.179879665374756\n",
            "158: loss: 7.764402866363525\n",
            "159: loss: 19.538515090942383\n",
            "160: loss: 8.554906845092773\n",
            "161: loss: 6.437376976013184\n",
            "162: loss: 11.028260231018066\n",
            "163: loss: 9.230269432067871\n",
            "164: loss: 16.509721755981445\n",
            "165: loss: 13.648387908935547\n",
            "166: loss: 15.098649978637695\n",
            "167: loss: 24.010791778564453\n",
            "168: loss: 14.464376449584961\n",
            "169: loss: 8.860456466674805\n",
            "170: loss: 4.633585453033447\n",
            "171: loss: 16.4110050201416\n",
            "172: loss: 3.879624366760254\n",
            "173: loss: 9.251388549804688\n",
            "174: loss: 2.650489091873169\n",
            "175: loss: 14.536965370178223\n",
            "176: loss: 10.794172286987305\n",
            "177: loss: 9.15794849395752\n",
            "178: loss: 3.000556230545044\n",
            "179: loss: 11.329529762268066\n",
            "180: loss: 12.863273620605469\n",
            "181: loss: 10.027546882629395\n",
            "182: loss: 4.864718437194824\n",
            "183: loss: 8.380252838134766\n",
            "184: loss: 11.651396751403809\n",
            "185: loss: 10.519129753112793\n",
            "186: loss: 5.3495001792907715\n",
            "187: loss: 19.918319702148438\n",
            "188: loss: 7.945709228515625\n",
            "189: loss: 16.760467529296875\n",
            "190: loss: 10.280864715576172\n",
            "191: loss: 6.924683094024658\n",
            "192: loss: 4.206191539764404\n",
            "193: loss: 3.9332966804504395\n",
            "194: loss: 9.348018646240234\n",
            "195: loss: 10.405506134033203\n",
            "196: loss: 4.955234527587891\n",
            "197: loss: 10.289129257202148\n",
            "198: loss: 13.549455642700195\n",
            "199: loss: 5.608366012573242\n",
            "200: loss: 9.773880004882812\n",
            "200: valid loss 9.295348167419434\n",
            "201: loss: 10.386340141296387\n",
            "202: loss: 5.8189697265625\n",
            "203: loss: 15.211191177368164\n",
            "204: loss: 17.900999069213867\n",
            "205: loss: 12.424398422241211\n",
            "206: loss: 6.201162815093994\n",
            "207: loss: 11.469035148620605\n",
            "208: loss: 4.4073100090026855\n",
            "209: loss: 10.24612045288086\n",
            "210: loss: 12.854374885559082\n",
            "211: loss: 8.28695297241211\n",
            "212: loss: 6.387476921081543\n",
            "213: loss: 14.069718360900879\n",
            "214: loss: 8.665060997009277\n",
            "215: loss: 10.78384017944336\n",
            "216: loss: 14.225297927856445\n",
            "217: loss: 9.564292907714844\n",
            "218: loss: 10.071474075317383\n",
            "219: loss: 12.952618598937988\n",
            "220: loss: 8.473542213439941\n",
            "221: loss: 6.991321563720703\n",
            "222: loss: 10.893101692199707\n",
            "223: loss: 9.417513847351074\n",
            "224: loss: 9.419631958007812\n",
            "225: loss: 7.892162322998047\n",
            "226: loss: 7.22645378112793\n",
            "227: loss: 3.1745452880859375\n",
            "228: loss: 3.9526851177215576\n",
            "229: loss: 12.046920776367188\n",
            "230: loss: 11.17655086517334\n",
            "231: loss: 6.251651287078857\n",
            "232: loss: 3.925159454345703\n",
            "233: loss: 3.183635711669922\n",
            "234: loss: 15.010189056396484\n",
            "235: loss: 9.795775413513184\n",
            "236: loss: 5.310702323913574\n",
            "237: loss: 9.708793640136719\n",
            "238: loss: 15.709178924560547\n",
            "239: loss: 4.805912494659424\n",
            "240: loss: 7.2387003898620605\n",
            "241: loss: 7.285252571105957\n",
            "242: loss: 10.390547752380371\n",
            "243: loss: 7.33537483215332\n",
            "244: loss: 15.079296112060547\n",
            "245: loss: 8.81619930267334\n",
            "246: loss: 14.648140907287598\n",
            "247: loss: 9.549981117248535\n",
            "248: loss: 9.382540702819824\n",
            "249: loss: 7.298291206359863\n",
            "250: loss: 24.797264099121094\n",
            "251: loss: 11.315327644348145\n",
            "252: loss: 12.379995346069336\n",
            "253: loss: 15.00689697265625\n",
            "254: loss: 11.408889770507812\n",
            "255: loss: 12.698637962341309\n",
            "256: loss: 9.321707725524902\n",
            "257: loss: 12.075300216674805\n",
            "258: loss: 13.287875175476074\n",
            "259: loss: 7.301335334777832\n",
            "260: loss: 5.328417778015137\n",
            "261: loss: 3.6045687198638916\n",
            "262: loss: 6.245426654815674\n",
            "263: loss: 3.060363292694092\n",
            "264: loss: 12.906502723693848\n",
            "265: loss: 9.208146095275879\n",
            "266: loss: 10.270552635192871\n",
            "267: loss: 3.515791177749634\n",
            "268: loss: 7.50455904006958\n",
            "269: loss: 7.673238277435303\n",
            "270: loss: 5.095200061798096\n",
            "271: loss: 6.412439346313477\n",
            "272: loss: 13.180947303771973\n",
            "273: loss: 6.10203218460083\n",
            "274: loss: 10.695387840270996\n",
            "275: loss: 11.324250221252441\n",
            "276: loss: 2.4669718742370605\n",
            "277: loss: 12.479389190673828\n",
            "278: loss: 12.897527694702148\n",
            "279: loss: 3.929004430770874\n",
            "280: loss: 18.236690521240234\n",
            "281: loss: 6.94895076751709\n",
            "282: loss: 7.370182514190674\n",
            "283: loss: 5.1930084228515625\n",
            "284: loss: 6.488647937774658\n",
            "285: loss: 5.016634941101074\n",
            "286: loss: 7.7071404457092285\n",
            "287: loss: 13.857464790344238\n",
            "288: loss: 10.254945755004883\n",
            "289: loss: 5.401798725128174\n",
            "290: loss: 5.363518714904785\n",
            "291: loss: 9.369043350219727\n",
            "292: loss: 12.383349418640137\n",
            "293: loss: 12.818178176879883\n",
            "294: loss: 8.66353988647461\n",
            "295: loss: 9.393872261047363\n",
            "296: loss: 11.051365852355957\n",
            "297: loss: 11.534158706665039\n",
            "298: loss: 4.993067741394043\n",
            "299: loss: 6.672845363616943\n",
            "300: loss: 3.65242338180542\n",
            "300: valid loss 9.209403038024902\n",
            "301: loss: 15.812151908874512\n",
            "302: loss: 5.721700191497803\n",
            "303: loss: 4.754734039306641\n",
            "304: loss: 12.768176078796387\n",
            "305: loss: 11.03198528289795\n",
            "306: loss: 12.254036903381348\n",
            "307: loss: 8.412104606628418\n",
            "308: loss: 16.016117095947266\n",
            "309: loss: 10.1317777633667\n",
            "310: loss: 5.2229390144348145\n",
            "311: loss: 3.7404227256774902\n",
            "312: loss: 10.24466609954834\n",
            "313: loss: 4.457277774810791\n",
            "314: loss: 9.804230690002441\n",
            "315: loss: 14.76522159576416\n",
            "316: loss: 6.635900974273682\n",
            "317: loss: 3.3434691429138184\n",
            "318: loss: 7.477949619293213\n",
            "319: loss: 15.323756217956543\n",
            "320: loss: 8.544485092163086\n",
            "321: loss: 3.6489031314849854\n",
            "322: loss: 8.279485702514648\n",
            "323: loss: 4.570096015930176\n",
            "324: loss: 5.891483783721924\n",
            "325: loss: 11.08410358428955\n",
            "326: loss: 5.223853588104248\n",
            "327: loss: 9.100114822387695\n",
            "328: loss: 9.902271270751953\n",
            "329: loss: 10.247673988342285\n",
            "330: loss: 8.80726146697998\n",
            "331: loss: 10.582951545715332\n",
            "332: loss: 8.978320121765137\n",
            "333: loss: 14.390325546264648\n",
            "334: loss: 11.292848587036133\n",
            "335: loss: 6.526447772979736\n",
            "336: loss: 13.390144348144531\n",
            "337: loss: 10.842138290405273\n",
            "338: loss: 8.705201148986816\n",
            "339: loss: 6.934048175811768\n",
            "340: loss: 6.82988166809082\n",
            "341: loss: 11.2161865234375\n",
            "342: loss: 7.259041786193848\n",
            "343: loss: 4.029686450958252\n",
            "344: loss: 2.8291573524475098\n",
            "345: loss: 7.708576679229736\n",
            "346: loss: 7.767373561859131\n",
            "347: loss: 6.252756118774414\n",
            "348: loss: 3.981095790863037\n",
            "349: loss: 6.0287933349609375\n",
            "350: loss: 12.058406829833984\n",
            "351: loss: 5.560020446777344\n",
            "352: loss: 8.903828620910645\n",
            "353: loss: 5.682636737823486\n",
            "354: loss: 7.783308506011963\n",
            "355: loss: 2.935157299041748\n",
            "356: loss: 7.04999303817749\n",
            "357: loss: 4.831159591674805\n",
            "358: loss: 10.517797470092773\n",
            "359: loss: 10.896217346191406\n",
            "360: loss: 6.517188549041748\n",
            "361: loss: 14.693154335021973\n",
            "362: loss: 7.819972038269043\n",
            "363: loss: 3.4159979820251465\n",
            "364: loss: 11.270076751708984\n",
            "365: loss: 7.0280985832214355\n",
            "366: loss: 13.51318073272705\n",
            "367: loss: 9.467573165893555\n",
            "368: loss: 7.704071998596191\n",
            "369: loss: 9.517096519470215\n",
            "370: loss: 8.965287208557129\n",
            "371: loss: 8.29425048828125\n",
            "372: loss: 4.612809658050537\n",
            "373: loss: 3.4579975605010986\n",
            "374: loss: 9.02281665802002\n",
            "375: loss: 7.252453327178955\n",
            "376: loss: 8.577942848205566\n",
            "377: loss: 8.516298294067383\n",
            "378: loss: 6.089172840118408\n",
            "379: loss: 8.779411315917969\n",
            "380: loss: 16.29581069946289\n",
            "381: loss: 9.889933586120605\n",
            "382: loss: 5.882906436920166\n",
            "383: loss: 5.1401472091674805\n",
            "384: loss: 8.452082633972168\n",
            "385: loss: 8.41934871673584\n",
            "386: loss: 8.586036682128906\n",
            "387: loss: 9.989850044250488\n",
            "388: loss: 10.552021026611328\n",
            "389: loss: 8.047395706176758\n",
            "390: loss: 8.345303535461426\n",
            "391: loss: 9.340354919433594\n",
            "392: loss: 9.849687576293945\n",
            "393: loss: 6.515598773956299\n",
            "394: loss: 4.77715539932251\n",
            "395: loss: 5.9690775871276855\n",
            "396: loss: 3.415239095687866\n",
            "397: loss: 3.6489243507385254\n",
            "398: loss: 2.8989243507385254\n",
            "399: loss: 36.91341018676758\n",
            "400: loss: 3.9546115398406982\n",
            "400: valid loss 4.8638787269592285\n",
            "401: loss: 14.803420066833496\n",
            "402: loss: 6.954507827758789\n",
            "403: loss: 11.985372543334961\n",
            "404: loss: 6.102726459503174\n",
            "405: loss: 5.471421241760254\n",
            "406: loss: 5.969363689422607\n",
            "407: loss: 5.63850736618042\n",
            "408: loss: 12.492854118347168\n",
            "409: loss: 12.329204559326172\n",
            "410: loss: 4.422123908996582\n",
            "411: loss: 3.0672707557678223\n",
            "412: loss: 7.780176639556885\n",
            "413: loss: 8.899425506591797\n",
            "414: loss: 12.475537300109863\n",
            "415: loss: 12.181475639343262\n",
            "416: loss: 4.0352702140808105\n",
            "417: loss: 7.183684825897217\n",
            "418: loss: 5.780305862426758\n",
            "419: loss: 7.817781925201416\n",
            "420: loss: 7.421870231628418\n",
            "421: loss: 12.81320858001709\n",
            "422: loss: 4.6233344078063965\n",
            "423: loss: 11.60875129699707\n",
            "424: loss: 4.97572660446167\n",
            "425: loss: 12.148723602294922\n",
            "426: loss: 7.43220853805542\n",
            "427: loss: 7.2240681648254395\n",
            "428: loss: 4.237536430358887\n",
            "429: loss: 2.7211380004882812\n",
            "430: loss: 9.368415832519531\n",
            "431: loss: 8.480408668518066\n",
            "432: loss: 2.3783843517303467\n",
            "433: loss: 4.270447254180908\n",
            "434: loss: 8.986810684204102\n",
            "435: loss: 14.105932235717773\n",
            "436: loss: 8.41506290435791\n",
            "437: loss: 2.841156244277954\n",
            "438: loss: 2.9828240871429443\n",
            "439: loss: 10.465734481811523\n",
            "440: loss: 3.75595760345459\n",
            "441: loss: 11.738438606262207\n",
            "442: loss: 8.23703384399414\n",
            "443: loss: 3.086477041244507\n",
            "444: loss: 11.391486167907715\n",
            "445: loss: 4.489390850067139\n",
            "446: loss: 4.870757579803467\n",
            "447: loss: 6.7754130363464355\n",
            "448: loss: 3.9005184173583984\n",
            "449: loss: 7.776638031005859\n",
            "450: loss: 7.282146453857422\n",
            "451: loss: 5.0295515060424805\n",
            "452: loss: 14.28702163696289\n",
            "453: loss: 3.1640512943267822\n",
            "454: loss: 12.465692520141602\n",
            "455: loss: 7.568619728088379\n",
            "456: loss: 3.4061882495880127\n",
            "457: loss: 2.519456624984741\n",
            "458: loss: 9.404472351074219\n",
            "459: loss: 5.251014232635498\n",
            "460: loss: 7.668331146240234\n",
            "461: loss: 8.682124137878418\n",
            "462: loss: 7.8307366371154785\n",
            "463: loss: 6.82838249206543\n",
            "464: loss: 8.151009559631348\n",
            "465: loss: 6.127635478973389\n",
            "466: loss: 7.676154613494873\n",
            "467: loss: 16.248348236083984\n",
            "468: loss: 5.340299129486084\n",
            "469: loss: 10.415846824645996\n",
            "470: loss: 5.263247489929199\n",
            "471: loss: 10.421682357788086\n",
            "472: loss: 6.392790794372559\n",
            "473: loss: 7.3534393310546875\n",
            "474: loss: 2.8362302780151367\n",
            "475: loss: 9.6482515335083\n",
            "476: loss: 3.557816743850708\n",
            "477: loss: 2.305952310562134\n",
            "478: loss: 3.0920629501342773\n",
            "479: loss: 11.3387451171875\n",
            "480: loss: 6.478085041046143\n",
            "481: loss: 3.8035454750061035\n",
            "482: loss: 8.14316177368164\n",
            "483: loss: 2.044123888015747\n",
            "484: loss: 6.764974117279053\n",
            "485: loss: 6.144720554351807\n",
            "486: loss: 11.16623592376709\n",
            "487: loss: 8.374749183654785\n",
            "488: loss: 3.0208449363708496\n",
            "489: loss: 7.146480083465576\n",
            "490: loss: 7.562228679656982\n",
            "491: loss: 3.1608688831329346\n",
            "492: loss: 5.741055488586426\n",
            "493: loss: 6.952703952789307\n",
            "494: loss: 8.724234580993652\n",
            "495: loss: 8.433121681213379\n",
            "496: loss: 6.095531463623047\n",
            "497: loss: 7.278109073638916\n",
            "498: loss: 8.396379470825195\n",
            "499: loss: 2.753452777862549\n",
            "500: loss: 11.35656452178955\n",
            "500: valid loss 3.525524139404297\n",
            "501: loss: 7.1285400390625\n",
            "502: loss: 15.305248260498047\n",
            "503: loss: 7.858391284942627\n",
            "504: loss: 5.393121719360352\n",
            "505: loss: 4.208061218261719\n",
            "506: loss: 2.9151594638824463\n",
            "507: loss: 4.105193138122559\n",
            "508: loss: 7.285400390625\n",
            "509: loss: 7.461727142333984\n",
            "510: loss: 4.000524520874023\n",
            "511: loss: 2.479003429412842\n",
            "512: loss: 10.70426082611084\n",
            "513: loss: 4.040889263153076\n",
            "514: loss: 4.725645542144775\n",
            "515: loss: 7.351879596710205\n",
            "516: loss: 4.11840295791626\n",
            "517: loss: 11.49023723602295\n",
            "518: loss: 7.919356346130371\n",
            "519: loss: 7.576058387756348\n",
            "520: loss: 3.4511735439300537\n",
            "521: loss: 10.146162986755371\n",
            "522: loss: 9.406512260437012\n",
            "523: loss: 7.647955417633057\n",
            "524: loss: 10.984901428222656\n",
            "525: loss: 3.6610450744628906\n",
            "526: loss: 7.769800186157227\n",
            "527: loss: 7.138788223266602\n",
            "528: loss: 3.046940803527832\n",
            "529: loss: 5.636919975280762\n",
            "530: loss: 7.66130256652832\n",
            "531: loss: 6.451492786407471\n",
            "532: loss: 7.170401573181152\n",
            "533: loss: 3.079922676086426\n",
            "534: loss: 3.390718698501587\n",
            "535: loss: 3.560492992401123\n",
            "536: loss: 2.4045629501342773\n",
            "537: loss: 7.768751621246338\n",
            "538: loss: 10.033419609069824\n",
            "539: loss: 4.6877522468566895\n",
            "540: loss: 7.413421154022217\n",
            "541: loss: 8.449905395507812\n",
            "542: loss: 8.882210731506348\n",
            "543: loss: 3.300205707550049\n",
            "544: loss: 3.0928080081939697\n",
            "545: loss: 3.635988473892212\n",
            "546: loss: 3.894380569458008\n",
            "547: loss: 3.2791693210601807\n",
            "548: loss: 3.863954544067383\n",
            "549: loss: 4.578306198120117\n",
            "550: loss: 10.395373344421387\n",
            "551: loss: 11.534724235534668\n",
            "552: loss: 7.805845737457275\n",
            "553: loss: 3.3749234676361084\n",
            "554: loss: 8.455578804016113\n",
            "555: loss: 2.956296920776367\n",
            "556: loss: 2.780534505844116\n",
            "557: loss: 10.693385124206543\n",
            "558: loss: 3.8343122005462646\n",
            "559: loss: 3.4935901165008545\n",
            "560: loss: 6.900368690490723\n",
            "561: loss: 2.9319000244140625\n",
            "562: loss: 8.957269668579102\n",
            "563: loss: 11.98892879486084\n",
            "564: loss: 3.6794447898864746\n",
            "565: loss: 5.502145290374756\n",
            "566: loss: 3.2689223289489746\n",
            "567: loss: 9.19139289855957\n",
            "568: loss: 9.645215034484863\n",
            "569: loss: 4.260256290435791\n",
            "570: loss: 3.6441538333892822\n",
            "571: loss: 2.921844720840454\n",
            "572: loss: 7.860307216644287\n",
            "573: loss: 8.255913734436035\n",
            "574: loss: 5.90919828414917\n",
            "575: loss: 5.939949989318848\n",
            "576: loss: 8.521626472473145\n",
            "577: loss: 5.7306952476501465\n",
            "578: loss: 6.408502578735352\n",
            "579: loss: 4.24779748916626\n",
            "580: loss: 3.65842342376709\n",
            "581: loss: 10.987927436828613\n",
            "582: loss: 5.254595756530762\n",
            "583: loss: 6.927026271820068\n",
            "584: loss: 3.5169425010681152\n",
            "585: loss: 10.20051383972168\n",
            "586: loss: 5.416869163513184\n",
            "587: loss: 14.725865364074707\n",
            "588: loss: 5.806838035583496\n",
            "589: loss: 4.123495578765869\n",
            "590: loss: 7.940128326416016\n",
            "591: loss: 9.489717483520508\n",
            "592: loss: 4.424499034881592\n",
            "593: loss: 5.526762008666992\n",
            "594: loss: 10.079972267150879\n",
            "595: loss: 7.016617298126221\n",
            "596: loss: 6.440818786621094\n",
            "597: loss: 3.334744930267334\n",
            "598: loss: 4.927377700805664\n",
            "599: loss: 6.505716800689697\n",
            "600: loss: 3.3080875873565674\n",
            "600: valid loss 6.760676860809326\n",
            "601: loss: 9.488181114196777\n",
            "602: loss: 3.6408803462982178\n",
            "603: loss: 2.7889211177825928\n",
            "604: loss: 9.542526245117188\n",
            "605: loss: 4.381335735321045\n",
            "606: loss: 5.819703102111816\n",
            "607: loss: 7.170708656311035\n",
            "608: loss: 6.649231910705566\n",
            "609: loss: 12.629867553710938\n",
            "610: loss: 3.139312505722046\n",
            "611: loss: 9.563294410705566\n",
            "612: loss: 8.316137313842773\n",
            "613: loss: 3.015427350997925\n",
            "614: loss: 6.538702487945557\n",
            "615: loss: 5.553601264953613\n",
            "616: loss: 4.28934907913208\n",
            "617: loss: 5.1374616622924805\n",
            "618: loss: 2.526130437850952\n",
            "619: loss: 6.902407169342041\n",
            "620: loss: 7.200587272644043\n",
            "621: loss: 10.644014358520508\n",
            "622: loss: 6.750687122344971\n",
            "623: loss: 6.844180107116699\n",
            "624: loss: 9.268231391906738\n",
            "625: loss: 2.569366931915283\n",
            "626: loss: 11.721814155578613\n",
            "627: loss: 8.003260612487793\n",
            "628: loss: 6.567483901977539\n",
            "629: loss: 5.003666400909424\n",
            "630: loss: 4.613449573516846\n",
            "631: loss: 2.7162282466888428\n",
            "632: loss: 10.6549072265625\n",
            "633: loss: 4.353385925292969\n",
            "634: loss: 8.98774528503418\n",
            "635: loss: 7.071572780609131\n",
            "636: loss: 7.441464424133301\n",
            "637: loss: 6.12154483795166\n",
            "638: loss: 10.22620677947998\n",
            "639: loss: 5.403313159942627\n",
            "640: loss: 6.051329612731934\n",
            "641: loss: 3.9809253215789795\n",
            "642: loss: 3.4213802814483643\n",
            "643: loss: 3.6151304244995117\n",
            "644: loss: 9.668155670166016\n",
            "645: loss: 4.489932060241699\n",
            "646: loss: 9.283835411071777\n",
            "647: loss: 6.330300807952881\n",
            "648: loss: 2.2389583587646484\n",
            "649: loss: 6.186187267303467\n",
            "650: loss: 8.76082706451416\n",
            "651: loss: 7.87568998336792\n",
            "652: loss: 6.130061626434326\n",
            "653: loss: 5.171473979949951\n",
            "654: loss: 5.531253814697266\n",
            "655: loss: 11.247908592224121\n",
            "656: loss: 10.768292427062988\n",
            "657: loss: 5.798830986022949\n",
            "658: loss: 8.899384498596191\n",
            "659: loss: 5.209799766540527\n",
            "660: loss: 7.344855308532715\n",
            "661: loss: 3.0550622940063477\n",
            "662: loss: 6.255723476409912\n",
            "663: loss: 8.582276344299316\n",
            "664: loss: 6.765028476715088\n",
            "665: loss: 4.863638401031494\n",
            "666: loss: 4.921471118927002\n",
            "667: loss: 5.1321210861206055\n",
            "668: loss: 5.3845648765563965\n",
            "669: loss: 3.9861900806427\n",
            "670: loss: 3.024026870727539\n",
            "671: loss: 5.930997371673584\n",
            "672: loss: 6.0792460441589355\n",
            "673: loss: 3.873465061187744\n",
            "674: loss: 7.7810587882995605\n",
            "675: loss: 6.053597927093506\n",
            "676: loss: 6.281229496002197\n",
            "677: loss: 2.6670069694519043\n",
            "678: loss: 12.843863487243652\n",
            "679: loss: 5.976787090301514\n",
            "680: loss: 3.811856985092163\n",
            "681: loss: 3.049009084701538\n",
            "682: loss: 6.55539083480835\n",
            "683: loss: 4.58321475982666\n",
            "684: loss: 5.171506404876709\n",
            "685: loss: 6.2710862159729\n",
            "686: loss: 5.394968032836914\n",
            "687: loss: 7.877862453460693\n",
            "688: loss: 8.062360763549805\n",
            "689: loss: 7.91241979598999\n",
            "690: loss: 4.745962142944336\n",
            "691: loss: 7.556338310241699\n",
            "692: loss: 2.922100305557251\n",
            "693: loss: 3.095367908477783\n",
            "694: loss: 6.392955303192139\n",
            "695: loss: 4.750932216644287\n",
            "696: loss: 6.233842849731445\n",
            "697: loss: 6.569457054138184\n",
            "698: loss: 4.395331382751465\n",
            "699: loss: 8.194415092468262\n",
            "700: loss: 8.176070213317871\n",
            "700: valid loss 7.038633346557617\n",
            "701: loss: 13.573080062866211\n",
            "702: loss: 6.0105509757995605\n",
            "703: loss: 9.495688438415527\n",
            "704: loss: 8.245563507080078\n",
            "705: loss: 4.5947794914245605\n",
            "706: loss: 4.1271843910217285\n",
            "707: loss: 5.495874881744385\n",
            "708: loss: 4.9409871101379395\n",
            "709: loss: 5.980178356170654\n",
            "710: loss: 3.3604636192321777\n",
            "711: loss: 5.954895973205566\n",
            "712: loss: 5.82412052154541\n",
            "713: loss: 2.612140417098999\n",
            "714: loss: 5.189124584197998\n",
            "715: loss: 2.4956297874450684\n",
            "716: loss: 3.0216081142425537\n",
            "717: loss: 7.096759796142578\n",
            "718: loss: 7.170742511749268\n",
            "719: loss: 4.5249176025390625\n",
            "720: loss: 4.766158580780029\n",
            "721: loss: 4.505252361297607\n",
            "722: loss: 7.59471321105957\n",
            "723: loss: 7.225018501281738\n",
            "724: loss: 5.357931613922119\n",
            "725: loss: 6.943983554840088\n",
            "726: loss: 6.926379680633545\n",
            "727: loss: 5.63617467880249\n",
            "728: loss: 6.199129581451416\n",
            "729: loss: 5.755046367645264\n",
            "730: loss: 5.635849475860596\n",
            "731: loss: 5.952267169952393\n",
            "732: loss: 6.734717845916748\n",
            "733: loss: 9.354620933532715\n",
            "734: loss: 11.167204856872559\n",
            "735: loss: 4.161908149719238\n",
            "736: loss: 2.4879209995269775\n",
            "737: loss: 3.9419853687286377\n",
            "738: loss: 3.370271682739258\n",
            "739: loss: 7.893208980560303\n",
            "740: loss: 8.865717887878418\n",
            "741: loss: 8.851862907409668\n",
            "742: loss: 3.1377148628234863\n",
            "743: loss: 6.274712562561035\n",
            "744: loss: 7.616405010223389\n",
            "745: loss: 6.855708599090576\n",
            "746: loss: 4.009796619415283\n",
            "747: loss: 4.8175225257873535\n",
            "748: loss: 4.373836517333984\n",
            "749: loss: 6.582152843475342\n",
            "750: loss: 8.905925750732422\n",
            "751: loss: 5.155491828918457\n",
            "752: loss: 6.119578838348389\n",
            "753: loss: 3.084834575653076\n",
            "754: loss: 2.9057271480560303\n",
            "755: loss: 7.029034614562988\n",
            "756: loss: 6.577191352844238\n",
            "757: loss: 3.552323341369629\n",
            "758: loss: 4.626443386077881\n",
            "759: loss: 3.620978355407715\n",
            "760: loss: 7.710862159729004\n",
            "761: loss: 7.426788806915283\n",
            "762: loss: 7.714680194854736\n",
            "763: loss: 6.0314435958862305\n",
            "764: loss: 5.6246724128723145\n",
            "765: loss: 3.2556257247924805\n",
            "766: loss: 2.851188898086548\n",
            "767: loss: 6.877624988555908\n",
            "768: loss: 5.745338439941406\n",
            "769: loss: 5.968018531799316\n",
            "770: loss: 7.572798728942871\n",
            "771: loss: 4.783285617828369\n",
            "772: loss: 7.5997796058654785\n",
            "773: loss: 10.317610740661621\n",
            "774: loss: 10.614611625671387\n",
            "775: loss: 7.672842025756836\n",
            "776: loss: 7.7141923904418945\n",
            "777: loss: 6.34342098236084\n",
            "778: loss: 4.850525379180908\n",
            "779: loss: 11.525842666625977\n",
            "780: loss: 2.206225872039795\n",
            "781: loss: 2.8192577362060547\n",
            "782: loss: 6.770970821380615\n",
            "783: loss: 4.979269504547119\n",
            "784: loss: 8.216819763183594\n",
            "785: loss: 3.957305669784546\n",
            "786: loss: 5.2295613288879395\n",
            "787: loss: 4.595796585083008\n",
            "788: loss: 4.59218692779541\n",
            "789: loss: 5.79140567779541\n",
            "790: loss: 4.854538917541504\n",
            "791: loss: 7.900609970092773\n",
            "792: loss: 2.4230527877807617\n",
            "793: loss: 2.6919078826904297\n",
            "794: loss: 6.294684410095215\n",
            "795: loss: 5.065622806549072\n",
            "796: loss: 8.444181442260742\n",
            "797: loss: 3.941725015640259\n",
            "798: loss: 5.167778015136719\n",
            "799: loss: 8.200515747070312\n",
            "800: loss: 5.8208417892456055\n",
            "800: valid loss 2.3124918937683105\n",
            "801: loss: 6.126982688903809\n",
            "802: loss: 6.396356105804443\n",
            "803: loss: 4.927629470825195\n",
            "804: loss: 8.755494117736816\n",
            "805: loss: 3.3198390007019043\n",
            "806: loss: 3.0609772205352783\n",
            "807: loss: 6.942631244659424\n",
            "808: loss: 4.015524864196777\n",
            "809: loss: 5.463663578033447\n",
            "810: loss: 5.091485977172852\n",
            "811: loss: 4.947529315948486\n",
            "812: loss: 2.467681884765625\n",
            "813: loss: 3.5297117233276367\n",
            "814: loss: 6.084159851074219\n",
            "815: loss: 4.5430145263671875\n",
            "816: loss: 5.007498264312744\n",
            "817: loss: 6.256595134735107\n",
            "818: loss: 5.867347240447998\n",
            "819: loss: 3.617685556411743\n",
            "820: loss: 3.9325101375579834\n",
            "821: loss: 8.185951232910156\n",
            "822: loss: 5.9405927658081055\n",
            "823: loss: 2.49163818359375\n",
            "824: loss: 6.913264751434326\n",
            "825: loss: 4.000847816467285\n",
            "826: loss: 9.343149185180664\n",
            "827: loss: 4.46159029006958\n",
            "828: loss: 9.005289077758789\n",
            "829: loss: 10.012223243713379\n",
            "830: loss: 7.8530097007751465\n",
            "831: loss: 4.775908946990967\n",
            "832: loss: 5.386895179748535\n",
            "833: loss: 6.4260573387146\n",
            "834: loss: 4.780333518981934\n",
            "835: loss: 2.605656623840332\n",
            "836: loss: 2.8722362518310547\n",
            "837: loss: 7.057811260223389\n",
            "838: loss: 7.217161178588867\n",
            "839: loss: 4.50912618637085\n",
            "840: loss: 6.664675712585449\n",
            "841: loss: 5.694920063018799\n",
            "842: loss: 3.101437568664551\n",
            "843: loss: 9.215152740478516\n",
            "844: loss: 2.924734115600586\n",
            "845: loss: 3.286454677581787\n",
            "846: loss: 2.6879570484161377\n",
            "847: loss: 7.050304889678955\n",
            "848: loss: 3.874687671661377\n",
            "849: loss: 3.8094985485076904\n",
            "850: loss: 7.368256092071533\n",
            "851: loss: 9.266267776489258\n",
            "852: loss: 3.01522159576416\n",
            "853: loss: 6.185645580291748\n",
            "854: loss: 4.836458683013916\n",
            "855: loss: 5.34897518157959\n",
            "856: loss: 7.251692771911621\n",
            "857: loss: 2.920448064804077\n",
            "858: loss: 9.595990180969238\n",
            "859: loss: 3.289393186569214\n",
            "860: loss: 2.761253833770752\n",
            "861: loss: 5.006041049957275\n",
            "862: loss: 2.5266590118408203\n",
            "863: loss: 3.2607250213623047\n",
            "864: loss: 2.4352989196777344\n",
            "865: loss: 8.092068672180176\n",
            "866: loss: 7.385672569274902\n",
            "867: loss: 5.107989311218262\n",
            "868: loss: 5.037045955657959\n",
            "869: loss: 10.302054405212402\n",
            "870: loss: 4.795140743255615\n",
            "871: loss: 2.389849901199341\n",
            "872: loss: 2.7641446590423584\n",
            "873: loss: 2.1390881538391113\n",
            "874: loss: 3.7290427684783936\n",
            "875: loss: 7.62291145324707\n",
            "876: loss: 6.06493616104126\n",
            "877: loss: 4.056429862976074\n",
            "878: loss: 6.318676471710205\n",
            "879: loss: 5.223264217376709\n",
            "880: loss: 3.1918299198150635\n",
            "881: loss: 6.512085914611816\n",
            "882: loss: 9.27038860321045\n",
            "883: loss: 6.164529800415039\n",
            "884: loss: 4.8546061515808105\n",
            "885: loss: 2.828139066696167\n",
            "886: loss: 5.2140278816223145\n",
            "887: loss: 5.520323276519775\n",
            "888: loss: 5.973778247833252\n",
            "889: loss: 6.279990196228027\n",
            "890: loss: 4.635919094085693\n",
            "891: loss: 3.079354763031006\n",
            "892: loss: 4.862326145172119\n",
            "893: loss: 4.36815881729126\n",
            "894: loss: 5.03717041015625\n",
            "895: loss: 5.119357109069824\n",
            "896: loss: 10.011710166931152\n",
            "897: loss: 5.24552583694458\n",
            "898: loss: 5.571732997894287\n",
            "899: loss: 6.240218639373779\n",
            "900: loss: 4.580724716186523\n",
            "900: valid loss 5.870479583740234\n",
            "901: loss: 5.009898662567139\n",
            "902: loss: 2.49479079246521\n",
            "903: loss: 5.964077949523926\n",
            "904: loss: 5.221762657165527\n",
            "905: loss: 4.938637733459473\n",
            "906: loss: 2.539175271987915\n",
            "907: loss: 5.027657508850098\n",
            "908: loss: 6.295772552490234\n",
            "909: loss: 7.750334739685059\n",
            "910: loss: 5.668228626251221\n",
            "911: loss: 9.17592716217041\n",
            "912: loss: 6.568299293518066\n",
            "913: loss: 3.732200860977173\n",
            "914: loss: 6.540841579437256\n",
            "915: loss: 4.176575660705566\n",
            "916: loss: 5.499911785125732\n",
            "917: loss: 5.7917304039001465\n",
            "918: loss: 5.537088871002197\n",
            "919: loss: 4.786805152893066\n",
            "920: loss: 2.5683958530426025\n",
            "921: loss: 6.140038967132568\n",
            "922: loss: 5.290985584259033\n",
            "923: loss: 4.189902305603027\n",
            "924: loss: 3.649254083633423\n",
            "925: loss: 3.96698260307312\n",
            "926: loss: 5.4063544273376465\n",
            "927: loss: 5.918013095855713\n",
            "928: loss: 5.909751892089844\n",
            "929: loss: 4.351531982421875\n",
            "930: loss: 6.638047695159912\n",
            "931: loss: 2.891192674636841\n",
            "932: loss: 7.9198222160339355\n",
            "933: loss: 4.962161540985107\n",
            "934: loss: 6.3001179695129395\n",
            "935: loss: 8.453633308410645\n",
            "936: loss: 7.249369144439697\n",
            "937: loss: 6.0003252029418945\n",
            "938: loss: 4.6820831298828125\n",
            "939: loss: 5.571254253387451\n",
            "940: loss: 5.282649040222168\n",
            "941: loss: 7.149255275726318\n",
            "942: loss: 3.0423922538757324\n",
            "943: loss: 5.28346061706543\n",
            "944: loss: 7.705895900726318\n",
            "945: loss: 5.76740837097168\n",
            "946: loss: 5.837209224700928\n",
            "947: loss: 6.883150577545166\n",
            "948: loss: 5.009615898132324\n",
            "949: loss: 8.188568115234375\n",
            "950: loss: 4.615739822387695\n",
            "951: loss: 4.990799427032471\n",
            "952: loss: 5.109670162200928\n",
            "953: loss: 5.9024763107299805\n",
            "954: loss: 6.542097091674805\n",
            "955: loss: 6.117258548736572\n",
            "956: loss: 3.9458343982696533\n",
            "957: loss: 1.9344940185546875\n",
            "958: loss: 6.123027801513672\n",
            "959: loss: 7.1034417152404785\n",
            "960: loss: 6.985075950622559\n",
            "961: loss: 8.221501350402832\n",
            "962: loss: 6.341607093811035\n",
            "963: loss: 2.2578582763671875\n",
            "964: loss: 3.20717191696167\n",
            "965: loss: 6.464789867401123\n",
            "966: loss: 3.397350311279297\n",
            "967: loss: 6.543932914733887\n",
            "968: loss: 6.605556488037109\n",
            "969: loss: 6.978034973144531\n",
            "970: loss: 5.440450668334961\n",
            "971: loss: 5.066067218780518\n",
            "972: loss: 2.751668930053711\n",
            "973: loss: 2.609445810317993\n",
            "974: loss: 3.5050487518310547\n",
            "975: loss: 5.690140247344971\n",
            "976: loss: 4.166738510131836\n",
            "977: loss: 4.988705158233643\n",
            "978: loss: 4.4340362548828125\n",
            "979: loss: 5.366905212402344\n",
            "980: loss: 5.973190784454346\n",
            "981: loss: 5.652614116668701\n",
            "982: loss: 5.593941688537598\n",
            "983: loss: 8.483972549438477\n",
            "984: loss: 6.997035026550293\n",
            "985: loss: 8.771710395812988\n",
            "986: loss: 7.158821105957031\n",
            "987: loss: 5.340248107910156\n",
            "988: loss: 5.779254913330078\n",
            "989: loss: 3.8961212635040283\n",
            "990: loss: 6.458739280700684\n",
            "991: loss: 6.492593288421631\n",
            "992: loss: 4.392596244812012\n",
            "993: loss: 5.365271091461182\n",
            "994: loss: 3.8135244846343994\n",
            "995: loss: 5.0290751457214355\n",
            "996: loss: 2.259227752685547\n",
            "997: loss: 6.299313068389893\n",
            "998: loss: 4.564381122589111\n",
            "999: loss: 2.9488768577575684\n",
            "training complete\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from audiolm_pytorch import SoundStream, FineTransformer, FineTransformerTrainer\n",
        "\n",
        "#soundstream = SoundStream.init_and_load_from('/path/to/trained/soundstream.pt')\n",
        "\n",
        "fine_transformer = FineTransformer(\n",
        "    num_coarse_quantizers = 3,\n",
        "    num_fine_quantizers = 5,\n",
        "    codebook_size = 1024,\n",
        "    dim = 1024,\n",
        "    depth = 6,\n",
        "    audio_text_condition = True,\n",
        "    has_condition = True\n",
        ").cuda()\n",
        "\n",
        "trainer = FineTransformerTrainer(\n",
        "    transformer = fine_transformer,\n",
        "    codec = soundstream,\n",
        "    audio_conditioner = quantizer,\n",
        "    folder = '/content/drive/MyDrive/ArtML_Final/recordings',\n",
        "    batch_size = 1,\n",
        "    data_max_length = 320 * 32,\n",
        "    num_train_steps = 100\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "P2qDJenStrG6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afd14e67-b2b8-4ecf-9285-daa6b21e7236"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training with dataset of 2850 samples and validating with randomly splitted 150 samples\n",
            "do you want to clear previous experiment checkpoints and results? (y/n) y\n",
            "0: loss: 102.89920806884766\n",
            "0: valid loss 98.99147033691406\n",
            "0: saving model to results\n",
            "1: loss: 101.76252746582031\n",
            "2: loss: 169.89581298828125\n",
            "3: loss: 121.8134765625\n",
            "4: loss: 83.03973388671875\n",
            "5: loss: 67.33219909667969\n",
            "6: loss: 38.159908294677734\n",
            "7: loss: 87.90650939941406\n",
            "8: loss: 10.048135757446289\n",
            "9: loss: 92.53950500488281\n",
            "10: loss: 72.66663360595703\n",
            "11: loss: 42.208412170410156\n",
            "12: loss: 54.060035705566406\n",
            "13: loss: 44.994590759277344\n",
            "14: loss: 40.80534362792969\n",
            "15: loss: 53.74730682373047\n",
            "16: loss: 44.59950256347656\n",
            "17: loss: 39.492698669433594\n",
            "18: loss: 49.04771423339844\n",
            "19: loss: 41.361663818359375\n",
            "20: loss: 15.554722785949707\n",
            "21: loss: 33.83832550048828\n",
            "22: loss: 5.972051620483398\n",
            "23: loss: 41.04780197143555\n",
            "24: loss: 29.863597869873047\n",
            "25: loss: 33.68241500854492\n",
            "26: loss: 41.20784378051758\n",
            "27: loss: 25.864662170410156\n",
            "28: loss: 15.535605430603027\n",
            "29: loss: 27.160812377929688\n",
            "30: loss: 34.15532684326172\n",
            "31: loss: 5.469046592712402\n",
            "32: loss: 16.19690704345703\n",
            "33: loss: 20.42890167236328\n",
            "34: loss: 24.876445770263672\n",
            "35: loss: 8.559028625488281\n",
            "36: loss: 10.240582466125488\n",
            "37: loss: 27.72477149963379\n",
            "38: loss: 31.238086700439453\n",
            "39: loss: 37.26457977294922\n",
            "40: loss: 35.33523941040039\n",
            "41: loss: 11.363030433654785\n",
            "42: loss: 27.95556640625\n",
            "43: loss: 26.627004623413086\n",
            "44: loss: 31.791658401489258\n",
            "45: loss: 34.767066955566406\n",
            "46: loss: 22.946016311645508\n",
            "47: loss: 11.233165740966797\n",
            "48: loss: 26.61495018005371\n",
            "49: loss: 30.495325088500977\n",
            "50: loss: 21.680849075317383\n",
            "51: loss: 25.164409637451172\n",
            "52: loss: 5.889080047607422\n",
            "53: loss: 6.433304309844971\n",
            "54: loss: 7.755178451538086\n",
            "55: loss: 24.591842651367188\n",
            "56: loss: 18.327392578125\n",
            "57: loss: 18.585407257080078\n",
            "58: loss: 16.534175872802734\n",
            "59: loss: 18.940462112426758\n",
            "60: loss: 13.617855072021484\n",
            "61: loss: 8.148656845092773\n",
            "62: loss: 22.725522994995117\n",
            "63: loss: 19.404029846191406\n",
            "64: loss: 23.315126419067383\n",
            "65: loss: 3.434497833251953\n",
            "66: loss: 22.97702980041504\n",
            "67: loss: 3.7157950401306152\n",
            "68: loss: 20.05011749267578\n",
            "69: loss: 15.718652725219727\n",
            "70: loss: 6.943606853485107\n",
            "71: loss: 19.54616928100586\n",
            "72: loss: 29.809463500976562\n",
            "73: loss: 19.132184982299805\n",
            "74: loss: 11.413414001464844\n",
            "75: loss: 6.601516246795654\n",
            "76: loss: 3.125410556793213\n",
            "77: loss: 4.3951005935668945\n",
            "78: loss: 2.9446067810058594\n",
            "79: loss: 19.849361419677734\n",
            "80: loss: 31.590185165405273\n",
            "81: loss: 7.270202159881592\n",
            "82: loss: 19.848217010498047\n",
            "83: loss: 14.032973289489746\n",
            "84: loss: 11.474881172180176\n",
            "85: loss: 17.354347229003906\n",
            "86: loss: 4.597176551818848\n",
            "87: loss: 6.549139022827148\n",
            "88: loss: 3.791161060333252\n",
            "89: loss: 17.245725631713867\n",
            "90: loss: 4.739518165588379\n",
            "91: loss: 8.806058883666992\n",
            "92: loss: 28.933855056762695\n",
            "93: loss: 21.23818016052246\n",
            "94: loss: 7.839783191680908\n",
            "95: loss: 16.4653377532959\n",
            "96: loss: 14.639162063598633\n",
            "97: loss: 12.163145065307617\n",
            "98: loss: 8.15860366821289\n",
            "99: loss: 27.488996505737305\n",
            "training complete\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from audiolm_pytorch import AudioLM\n",
        "from musiclm_pytorch import MusicLM\n",
        "\n",
        "audiolm = AudioLM(\n",
        "    wav2vec = wav2vec,\n",
        "    codec = soundstream,\n",
        "    semantic_transformer = semantic_transformer,\n",
        "    coarse_transformer = coarse_transformer,\n",
        "    fine_transformer = fine_transformer\n",
        ")\n",
        "\n",
        "musiclm = MusicLM(\n",
        "    audio_lm = audiolm,\n",
        "    mulan_embed_quantizer = quantizer\n",
        ")"
      ],
      "metadata": {
        "id": "ptzxt88suF9y"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "music = musiclm('the crystalline sounds of the piano in a ballroom', num_samples = 1) # sample 4 and pick the top match with mulan"
      ],
      "metadata": {
        "id": "2TE2ojhCuZyx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b0f0940-9ae5-4dd3-8eca-66f1469f2f44"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "generating semantic: 100%|██████████| 2048/2048 [05:28<00:00,  6.23it/s]\n",
            "generating coarse: 100%|██████████| 512/512 [14:18<00:00,  1.68s/it]\n",
            "generating fine: 100%|██████████| 512/512 [26:19<00:00,  3.08s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(music)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "7soP5_SbKeFG",
        "outputId": "cab0cedd-fc0a-4108-ccbe-089ae066756a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-adf4ac7e1bcb>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmusic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'music' is not defined"
          ]
        }
      ]
    }
  ]
}